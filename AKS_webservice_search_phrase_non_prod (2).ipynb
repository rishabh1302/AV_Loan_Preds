{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Phrase Extraction\n",
    "\n",
    "<font color=\"blue\">\n",
    "Own By: Cognizant Academy\n",
    "</font>\n",
    "\n",
    "|Developer | Date | Department |\n",
    "|-------------|------|------------|\n",
    "| Arpan Ghosh| Sept 2020 | CDB-AIA-BAI-Data Science & Analytics |\n",
    "| Sutrishna Hazra| June 2021 | CDB-AIA-BAI-AI |\n",
    "| Rishabh Malhotra| June 2021| IT - Data & Analytics|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication and connect to the Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to work with MLMYLEARNNONPROD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Model\n",
    "from azureml.core import Environment, Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Run\n",
    "\n",
    "LOCAL_RUN = 'N'\n",
    "\n",
    "if LOCAL_RUN == 'N':\n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    ws = run.experiment.workspace\n",
    "else:\n",
    "    # Load the workspace from the saved config file\n",
    "    try:\n",
    "        with open('./setup_config.json') as setup_config_data:\n",
    "            setup_config = json.load(setup_config_data)\n",
    "    except ValueError as error:\n",
    "        print(\"Error type:\", type(error))\n",
    "        print(\"json.loads() ValueError for JSON object:\", error)\n",
    "\n",
    "    subscription_id = setup_config['subscription_id']\n",
    "    tenant_id = setup_config['tenant_id']\n",
    "    resource_group = setup_config['resource_group']\n",
    "    workspace_name = setup_config['workspace_name']\n",
    "\n",
    "\n",
    "    interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "\n",
    "\n",
    "    ws = Workspace(\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group=resource_group,\n",
    "        workspace_name=workspace_name,\n",
    "        auth=interactive_auth\n",
    "    )\n",
    "\n",
    "print('Ready to work with {}'.format(ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Pipeline to register the model via Computer Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AKS Deployment - in Non Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_web_service folder created.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'search_web_service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the webserice script and store in the experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting search_web_service/search_api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/search_api.py\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "##---- Developed by CDB-AIA-DS | Arpan Ghose (626636) & Sutrishna (747375)----##\n",
    "#------------------------------------------------------------------------------#\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import brown\n",
    "from nltk import word_tokenize\n",
    "import os\n",
    "import json\n",
    "from operator import itemgetter\n",
    "from itertools import chain, combinations\n",
    "import string\n",
    "import copy\n",
    "import queue\n",
    "from threading import Thread\n",
    "import re\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
    "#import request\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# This class is necessary to extract the useful noun phrases.\n",
    "\n",
    "\n",
    "class Noun_Phrase_Extraction(object):\n",
    "\n",
    "    brown_train = brown.tagged_sents(categories='news')\n",
    "\n",
    "    ##---- Regular Expression based Tagger definition ----##\n",
    "    regexp_tagger = nltk.RegexpTagger(\n",
    "        [\n",
    "            (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),\n",
    "            (r'(-|:|;)$', ':'),\n",
    "            (r'\\'*$', 'MD'),\n",
    "            (r'(The|the|A|a|An|an)$', 'AT'),\n",
    "            (r'.*able$', 'JJ'),\n",
    "            (r'^[A-Z].*$', 'NNP'),\n",
    "            (r'.*ness$', 'NN'),\n",
    "            (r'.*ly$', 'RB'),\n",
    "            (r'.*s$', 'NNS'),\n",
    "            (r'.*ing$', 'VBG'),\n",
    "            (r'.*ed$', 'VBD'),\n",
    "            (r'.*', 'NN')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    unigram_tagger = nltk.UnigramTagger(brown_train, backoff=regexp_tagger)\n",
    "    bigram_tagger = nltk.BigramTagger(brown_train, backoff=unigram_tagger)\n",
    "\n",
    "    ##---- Production Rules for Grammar Definition ----##\n",
    "    cfg = {}  # start symbol\n",
    "    cfg[\"NNP+NNP\"] = \"NNP\"\n",
    "    cfg[\"NN+NN\"] = \"NNI\"\n",
    "    cfg[\"NNI+NN\"] = \"NNI\"\n",
    "    cfg[\"JJ+JJ\"] = \"JJ\"\n",
    "    cfg[\"JJ+NN\"] = \"NNI\"\n",
    "\n",
    "    ##-- Constructor --##\n",
    "    def __init__(self, sentence):\n",
    "        self.sentence = sentence\n",
    "\n",
    "    ##---- Split the sentence into single words/tokens ----##\n",
    "    def tokenize_sentence(self, sentence):\n",
    "        #tokens = nltk.word_tokenize(sentence)\n",
    "        tokens = sentence.split(\" \")\n",
    "        return tokens\n",
    "\n",
    "    ##---- Normalize brown corpus' tags (\"NN\", \"NN-PL\", \"NNS\" > \"NN\") ----##\n",
    "    def normalize_tags(self, tagged):\n",
    "        n_tagged = []\n",
    "        for t in tagged:\n",
    "            if t[1] == \"NP-TL\" or t[1] == \"NP\":\n",
    "                n_tagged.append((t[0], \"NNP\"))\n",
    "                continue\n",
    "            if t[1].endswith(\"-TL\"):\n",
    "                n_tagged.append((t[0], t[1][:-3]))\n",
    "                continue\n",
    "            if t[1].endswith(\"S\"):\n",
    "                n_tagged.append((t[0], t[1][:-1]))\n",
    "                continue\n",
    "            n_tagged.append((t[0], t[1]))\n",
    "        return n_tagged\n",
    "\n",
    "    ##---- Extract the main topics by NNP/NNI/NN/CD ----##\n",
    "    def extract(self):\n",
    "        tokens = self.tokenize_sentence(self.sentence)\n",
    "        tags = self.normalize_tags(self.bigram_tagger.tag(tokens))\n",
    "        #print (tags)\n",
    "        merge = True\n",
    "        while merge:\n",
    "            merge = False\n",
    "            for x in range(0, len(tags) - 1):\n",
    "                t1 = tags[x]\n",
    "                t2 = tags[x + 1]\n",
    "                key = \"%s+%s\" % (t1[1], t2[1])\n",
    "                value = self.cfg.get(key, '')\n",
    "                if value:\n",
    "                    merge = True\n",
    "                    tags.pop(x)\n",
    "                    tags.pop(x)\n",
    "                    match = \"%s %s\" % (t1[0], t2[0])\n",
    "                    pos = value\n",
    "                    tags.insert(x, (match, pos))\n",
    "                    break\n",
    "\n",
    "        matches = []\n",
    "        for t in tags:\n",
    "            if (t[1] == \"NNP\" or t[1] == \"NNI\" or t[1] == \"NN\" or t[1] == \"CD\"):\n",
    "                matches.append(t[0])\n",
    "        return matches\n",
    "\n",
    "    ##---- Extract the main topics by VB/VBG ----##\n",
    "    def extract_2(self):\n",
    "\n",
    "        tokens = self.tokenize_sentence(self.sentence)\n",
    "        tags = self.normalize_tags(bigram_tagger.tag(tokens))\n",
    "        #tags = self.normalize_tags(trigram_tagger.tag(tokens))\n",
    "        #print (tags)\n",
    "        merge = True\n",
    "        while merge:\n",
    "            merge = False\n",
    "            for x in range(0, len(tags) - 1):\n",
    "                t1 = tags[x]\n",
    "                t2 = tags[x + 1]\n",
    "                key = \"%s+%s\" % (t1[1], t2[1])\n",
    "                value = cfg.get(key, '')\n",
    "                if value:\n",
    "                    merge = True\n",
    "                    tags.pop(x)\n",
    "                    tags.pop(x)\n",
    "                    match = \"%s %s\" % (t1[0], t2[0])\n",
    "                    pos = value\n",
    "                    tags.insert(x, (match, pos))\n",
    "                    break\n",
    "\n",
    "        matches = []\n",
    "        for t in tags:\n",
    "            if (t[1] == \"VB\" or t[1] == \"VBG\"):\n",
    "                matches.append(t[0])\n",
    "        return matches\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_for_market_place\n",
    "# This function is used to check for the market place name at the input query.\n",
    "# This function takes two parameters - user's search input query and list of\n",
    "# all market place name.\n",
    "\n",
    "\n",
    "def check_for_market_place(input_query, market_place):\n",
    "    print(\"Function: [check_for_market_place]\")\n",
    "    print(\"input_query in check_for_market_place: [%s]\" % input_query)\n",
    "    if (isinstance(input_query, list)):\n",
    "        input_query = \"\".join(input_query)\n",
    "    #print (input_query)\n",
    "    user_input = input_query.lower()\n",
    "    print(\"User Input: [%s]\" % user_input)\n",
    "\n",
    "    market_place_found = 0\n",
    "\n",
    "    for i in range(0, len(market_place)):\n",
    "        temp_item = market_place[i].lower()\n",
    "        if (user_input == temp_item):\n",
    "            market_place_found = temp_item\n",
    "            break\n",
    "\n",
    "    return market_place_found\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_for_delivery_mode\n",
    "# This function is used to check for the delivery mode name at the input query.\n",
    "\n",
    "\n",
    "def check_for_delivery_mode(\n",
    "        input_query,\n",
    "        temp_dict,\n",
    "        delivery_mode):\n",
    "    print(\"Function: [check_for_delivery_mode]\")\n",
    "    delivery_mode_found = 0\n",
    "\n",
    "    for i in range(0, len(delivery_mode)):\n",
    "        if ((input_query.lower() == delivery_mode[i].lower()) or\n",
    "                (input_query[0:-1].lower() == delivery_mode[i].lower())):\n",
    "            print(\"Delivery Mode found\")\n",
    "            temp_dict[\"deliveryModeFlag\"] = \"yes\"\n",
    "            temp_dict[\"deliveryMode\"] = delivery_mode[i].lower()\n",
    "            delivery_mode_found = 1\n",
    "            break\n",
    "\n",
    "    return delivery_mode_found\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_for_category\n",
    "# This function is used to check for the input query with primary and secondary\n",
    "# category. This function accepts three parameters - user's input query,\n",
    "# list of secondary categories, list of primary categories.\n",
    "\n",
    "\n",
    "def check_for_category(input_query, seco_category, prim_category):\n",
    "    if (isinstance(input_query, list)):\n",
    "        input_query = \"\".join(input_query)\n",
    "    user_input = input_query.lower()\n",
    "    print(\"User Input at function <check_for_category>: [%s]\" % user_input)\n",
    "\n",
    "    secondary_cat = 0\n",
    "    primary_cat = 0\n",
    "\n",
    "    for j in range(0, len(seco_category)):\n",
    "        temp_item = seco_category[j].lower()\n",
    "        if (user_input == temp_item):\n",
    "            secondary_cat = temp_item\n",
    "            break\n",
    "\n",
    "    for k in range(0, len(prim_category)):\n",
    "        temp_item = prim_category[k].lower()\n",
    "        if (user_input == temp_item):\n",
    "            primary_cat = temp_item\n",
    "            break\n",
    "\n",
    "    return secondary_cat, primary_cat\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_for_did_you_mean\n",
    "# This function is used to prepare the did you mean result. This function takes\n",
    "# two parameters - search input query and list of all unique tags.\n",
    "\n",
    "\n",
    "def check_for_did_you_mean(Search_String, tags_2):\n",
    "    print(\"check_for_did_you_mean {Search_String}: [%s]\" % Search_String)\n",
    "    qs_tokens = (Search_String.split())\n",
    "    qs_tokens_length = len(qs_tokens)\n",
    "    tags_2_len = len(tags_2)\n",
    "\n",
    "    high_score_tag = []\n",
    "    dict_1 = {}\n",
    "    for i in range(0, qs_tokens_length):\n",
    "        temp_1 = []\n",
    "        for j in range(0, tags_2_len):\n",
    "            temp_dict = {}\n",
    "            temp_dict[\"tag\"] = tags_2[j]\n",
    "            temp_dict[\"score\"] = difflib.SequenceMatcher(None, qs_tokens[i],\n",
    "                                                         tags_2[j]).ratio()\n",
    "            temp_1.append(temp_dict)\n",
    "        required_item = max(temp_1, key=lambda x: x['score'])\n",
    "        high_score_tag.append(required_item)\n",
    "    #print (\"high_score_tag: \", high_score_tag)\n",
    "    dym_tag = list(map(itemgetter(\"tag\"), high_score_tag))\n",
    "    #print (dym_tag)\n",
    "    dym_tag_str = \" \".join(dym_tag)\n",
    "    #print (\"didYouMean_str: [%s]\" %dym_tag_str)\n",
    "\n",
    "    if (Search_String != dym_tag_str.lower()):\n",
    "        return (dym_tag_str)\n",
    "    else:\n",
    "        return None\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: handle_nlp_extracted_phrase\n",
    "# This function is used to process the NLP works. This function takes\n",
    "# two parameters - input under NLP process and list of all unique tags.\n",
    "\n",
    "\n",
    "def handle_nlp_extracted_phrase(nlp_phrase, tags_2):\n",
    "    print(\"Function: [handle_nlp_extracted_phrase]\")\n",
    "    #print (\"Input nlp_phrase: [%s]\" %nlp_phrase)\n",
    "    tags_2_len = len(tags_2)\n",
    "\n",
    "    nlp_phrase_2 = re.sub(\n",
    "        '[ãèéªã½ã¼ã¹ãäÃ³ä½ç³ãå³ãä½ºç¹¹æ³¾ï²µàâÐÑÄÅÂêëìíö©ð»ñŒð½ñ‹ñ]', '',\n",
    "        nlp_phrase)\n",
    "    nlp_phrase_3 = re.sub(r\"\\W+|_\", \" \", str(nlp_phrase_2))\n",
    "    #print (\"nlp_phrase_3: \", nlp_phrase_3)\n",
    "\n",
    "    phrase = nlp_phrase_3.split(\" \")\n",
    "    #print (phrase)\n",
    "    #print (len(phrase))\n",
    "\n",
    "    phrase_2 = []\n",
    "    for i in range(0, len(phrase)):\n",
    "        if (phrase[i] not in phrase_2):\n",
    "            phrase_2.append(phrase[i])\n",
    "    #print (phrase_2)\n",
    "    #print (len(phrase_2))\n",
    "\n",
    "    exact_phrase_match = []\n",
    "    for i in range(0, len(phrase_2)):\n",
    "        for j in range(0, tags_2_len):\n",
    "            if (phrase_2[i].lower() == tags_2[j].lower()):\n",
    "                exact_phrase_match.append(phrase_2[i])\n",
    "                break\n",
    "\n",
    "    #print (exact_phrase_match)\n",
    "    return (exact_phrase_match)\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: process_single_word_input\n",
    "# This function is used to process the search input query of single word only.\n",
    "# This function checks for all posiible conditions from the business aspects\n",
    "# and then prepares the necessary tag field(s) of the NLU result.\n",
    "\n",
    "\n",
    "def process_single_word_input(\n",
    "        tokens,\n",
    "        temp_dict,\n",
    "        tags_2,\n",
    "        proficiency_level):\n",
    "\n",
    "    print(\"Function Name: [%s]\" % process_single_word_input)\n",
    "    tokens_str = \" \".join(tokens)\n",
    "    tokens_str = tokens_str.lower()\n",
    "\n",
    "    temp_dict[\"secondaryCategoryFlag\"] = \"no\"\n",
    "    temp_dict[\"primaryCategoryFlag\"] = \"no\"\n",
    "    temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"deliveryModeFlag\"] = \"no\"\n",
    "    temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "\n",
    "    temp_dict[\"phrase\"] = \"no\"\n",
    "    temp_dict[\"flagProficiency\"] = \"no\"\n",
    "    temp_dict[\"userSearchTags\"] = tokens_str\n",
    "\n",
    "    for i in range(0, len(proficiency_level)):\n",
    "        if (tokens_str == proficiency_level[i].lower()):\n",
    "            temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "            temp_dict[\"userProficiency_search\"] = tokens_str\n",
    "            temp_dict[\"userSearchTags\"] = \"no\"\n",
    "            break\n",
    "\n",
    "    if (\"no\" != temp_dict[\"userSearchTags\"]):\n",
    "        dym_val = check_for_did_you_mean(tokens_str, tags_2)\n",
    "        if (None is not dym_val):\n",
    "            temp_dict[\"userSearchTags\"] = \"no\"\n",
    "            temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "        else:\n",
    "            temp_dict[\"didYouMean\"] = \"no\"\n",
    "    return (temp_dict)\n",
    "\n",
    "## Function: process_two_words_input\n",
    "# This function works in a deterministic approach method, i.e. it considers the\n",
    "# user's search input in two words only and then it checks for all possible\n",
    "# combinations.\n",
    "\n",
    "\n",
    "def process_two_words_input(\n",
    "        tokens,\n",
    "        temp_dict,\n",
    "        seco_category,\n",
    "        prim_category,\n",
    "        delivery_mode,\n",
    "        market_place,\n",
    "        keywords_list,\n",
    "        tags_2,\n",
    "        all_items,\n",
    "        proficiency_level):\n",
    "\n",
    "    print(\"function: [process_two_words_input]\")\n",
    "\n",
    "    two_words_input_flag = 0\n",
    "\n",
    "    temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "    temp_dict[\"deliveryModeFlag\"] = \"no\"\n",
    "    temp_dict[\"flagProficiency\"] = \"no\"\n",
    "    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "    temp_dict[\"secondaryCategoryFlag\"] = \"no\"\n",
    "    temp_dict[\"primaryCategoryFlag\"] = \"no\"\n",
    "    temp_dict[\"marketPlaceFlag\"] = \"no\"\n",
    "\n",
    "    ##-----------------------------------------------------------------##\n",
    "    #activity_label_found = 0\n",
    "    lo_type_found = 0\n",
    "    delivery_mode_found = 0\n",
    "    market_place_found = 0\n",
    "    ##-- Wrong Input: <Activity Label> <LO Type> ----##\n",
    "    # Seminar Resource\n",
    "    if (0 == two_words_input_flag):\n",
    "        for j1 in range(0, len(delivery_mode)):\n",
    "            if ((tokens[0].lower() == delivery_mode[j1].lower()) or\n",
    "                    (tokens[0][0:-1].lower() == delivery_mode[j1].lower())):\n",
    "                temp_dict[\"deliveryModeFlag\"] = \"yes\"\n",
    "                temp_dict[\"deliveryMode\"] = delivery_mode[j1].lower()\n",
    "                delivery_mode_found = 1\n",
    "                break\n",
    "        for j2 in range(0, len(market_place)):\n",
    "            if ((tokens[0].lower() == market_place[j2].lower()) or\n",
    "                    (tokens[0][0:-1].lower() == market_place[j2].lower())):\n",
    "                temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                temp_dict[\"marketPlace\"] = market_place[j2].lower()\n",
    "                market_place_found = 1\n",
    "                break\n",
    "        for j3 in range(0, len(keywords_list)):\n",
    "            if ((tokens[0].lower() == keywords_list['value'][j3].lower()) or (\n",
    "                    tokens[0][0:-1].lower() == keywords_list['value'][j3].lower())):\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                temp_dict[\"learningObject\"] = keywords_list['key'][j3].lower()\n",
    "        for k in range(0, len(keywords_list)):\n",
    "            if ((tokens[1].lower() == keywords_list['value'][k].lower()) or (\n",
    "                    tokens[1][0:-1].lower() == keywords_list['value'][k].lower())):\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                temp_dict[\"learningObject\"] = keywords_list['key'][k].lower()\n",
    "                #print (\"Learning Object found at token 1\")\n",
    "                lo_type_found = 1\n",
    "                break\n",
    "        if ((1 == delivery_mode_found) or (1 == market_place_found)):\n",
    "            if (1 == lo_type_found):\n",
    "                #print (\"Condition gets satisfied\")\n",
    "                two_words_input_flag = 1\n",
    "                ## Correct Input ##\n",
    "            else:  # Seminar Python ##\n",
    "                temp_dict[\"phrase\"] = tokens[1].lower()\n",
    "                temp_dict[\"userSearchTags\"] = tokens[1].lower().split(\" \")\n",
    "                que_1 = queue.Queue()\n",
    "                t1 = Thread(target=lambda q1, a1, b1, c1: q1.put(\n",
    "                            check_for_category(a1, b1, c1)),\n",
    "                            args=(que_1, tokens[1].lower(),\n",
    "                                  seco_category, prim_category))\n",
    "                que_2 = queue.Queue()\n",
    "                t2 = Thread(target=lambda q2, a2, b2: q2.put(\n",
    "                            check_for_did_you_mean(a2, b2)),\n",
    "                            args=(que_2, tokens[1].lower(), tags_2))\n",
    "                que_3 = queue.Queue()\n",
    "                t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                            check_exact_skill_match(a3, b3)),\n",
    "                            args=(que_3, tokens[1].lower(), all_items))\n",
    "                que_4 = queue.Queue()\n",
    "                t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                            check_for_market_place(a4, b4)),\n",
    "                            args=(que_4, tokens[1].lower(), market_place))\n",
    "                t1.start()\n",
    "                t2.start()\n",
    "                t3.start()\n",
    "                t4.start()\n",
    "                t1.join()\n",
    "                t2.join()\n",
    "                t3.join()\n",
    "                t4.join()\n",
    "                scm, pcm = que_1.get()\n",
    "                if (0 != scm):\n",
    "                    temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"secondaryCategory\"] = scm\n",
    "                if (0 != pcm):\n",
    "                    temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"primaryCategory\"] = pcm\n",
    "                dym_val = que_2.get()\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                skill_match, associated_tags = que_3.get()\n",
    "                if (1 == skill_match):\n",
    "                    temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                    temp_dict[\"skillName\"] = tokens[1].lower()\n",
    "                market_place_flag = que_4.get()\n",
    "                if (0 != market_place_flag):\n",
    "                    temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                    temp_dict[\"marketPlace\"] = market_place_flag\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                two_words_input_flag = 1\n",
    "\n",
    "        # Java Training\n",
    "        # Python Artcle\n",
    "        else:\n",
    "            if (1 == lo_type_found):\n",
    "                # check for token 1 for activity level\n",
    "\n",
    "                que_1 = queue.Queue()\n",
    "                t1 = Thread(target=lambda q1, a1, b1, c1: q1.put(\n",
    "                            check_for_category(a1, b1, c1)),\n",
    "                            args=(que_1, tokens[0].lower(),\n",
    "                                  seco_category, prim_category))\n",
    "                que_2 = queue.Queue()\n",
    "                t2 = Thread(target=lambda q2, a2, b2: q2.put(\n",
    "                            check_for_did_you_mean(a2, b2)),\n",
    "                            args=(que_2, tokens[0].lower(), tags_2))\n",
    "                que_3 = queue.Queue()\n",
    "                t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                            check_exact_skill_match(a3, b3)),\n",
    "                            args=(que_3, tokens[0].lower(), all_items))\n",
    "                que_4 = queue.Queue()\n",
    "                t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                            check_for_market_place(a4, b4)),\n",
    "                            args=(que_4, tokens[0].lower(), market_place))\n",
    "                t1.start()\n",
    "                t2.start()\n",
    "                t3.start()\n",
    "                t4.start()\n",
    "                t1.join()\n",
    "                t2.join()\n",
    "                t3.join()\n",
    "                t4.join()\n",
    "                scm, pcm = que_1.get()\n",
    "                if (0 != scm):\n",
    "                    temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"secondaryCategory\"] = scm\n",
    "                if (0 != pcm):\n",
    "                    temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"primaryCategory\"] = pcm\n",
    "                dym_val = que_2.get()\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                skill_match, associated_tags = que_3.get()\n",
    "                if (1 == skill_match):\n",
    "                    temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                    temp_dict[\"skillName\"] = tokens[0].lower()\n",
    "                market_place_flag = que_4.get()\n",
    "                if (0 != market_place_flag):\n",
    "                    temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                    temp_dict[\"marketPlace\"] = market_place_flag\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                two_words_input_flag = 1\n",
    "    ##----------------------------------------------------------------##\n",
    "\n",
    "    ##----------------------------------------------------------------##\n",
    "    #activity_label_found = 0\n",
    "    lo_type_found = 0\n",
    "    delivery_mode_found = 0\n",
    "    market_place_found = 0\n",
    "    ##-- Wrong Input: <LO Type> <Activity Label> ----##\n",
    "    # Resource Seminar\n",
    "    if (0 == two_words_input_flag):\n",
    "\n",
    "        for j1 in range(0, len(delivery_mode)):\n",
    "            if ((tokens[1].lower() == delivery_mode[j1].lower()) or\n",
    "                    (tokens[1][0:-1].lower() == delivery_mode[j1].lower())):\n",
    "                temp_dict[\"deliveryModeFlag\"] = \"yes\"\n",
    "                temp_dict[\"deliveryMode\"] = delivery_mode[j1].lower()\n",
    "                delivery_mode_found = 1\n",
    "                break\n",
    "        for j2 in range(0, len(market_place)):\n",
    "            if ((tokens[1].lower() == market_place[j2].lower()) or\n",
    "                    (tokens[1][0:-1].lower() == market_place[j2].lower())):\n",
    "                temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                temp_dict[\"marketPlace\"] = market_place[j2].lower()\n",
    "                market_place_found = 1\n",
    "                break\n",
    "        for j3 in range(0, len(keywords_list)):\n",
    "            if ((tokens[0].lower() == keywords_list['value'][j3].lower()) or (\n",
    "                    tokens[0][0:-1].lower() == keywords_list['value'][j3].lower())):\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                temp_dict[\"learningObject\"] = keywords_list['key'][j3].lower()\n",
    "        for k in range(0, len(keywords_list)):\n",
    "            if ((tokens[1].lower() == keywords_list['value'][k].lower()) or (\n",
    "                    tokens[1][0:-1].lower() == keywords_list['value'][k].lower())):\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                temp_dict[\"learningObject\"] = keywords_list['key'][k].lower()\n",
    "                #print (\"Learning Object found at token 0\")\n",
    "                lo_type_found = 1\n",
    "                break\n",
    "        #print ('temp_dict[\"activityLabelFlag\"]: ', temp_dict[\"activityLabelFlag\"])\n",
    "        #print ('temp_dict[\"deliveryModeFlag\"]: ', temp_dict[\"deliveryModeFlag\"])\n",
    "        #print ('temp_dict[\"marketPlaceFlag\"]: ', temp_dict[\"marketPlaceFlag\"])\n",
    "\n",
    "        if ((1 == delivery_mode_found) or (1 == market_place_found)):\n",
    "            if (1 == lo_type_found):\n",
    "                two_words_input_flag = 1\n",
    "            ## Correct Input ##\n",
    "            else:  # Python Seminar ##\n",
    "                temp_dict[\"phrase\"] = tokens[0].lower()\n",
    "                temp_dict[\"userSearchTags\"] = tokens[0].lower().split(\" \")\n",
    "                que_1 = queue.Queue()\n",
    "                t1 = Thread(target=lambda q1, a1, b1, c1: q1.put(\n",
    "                            check_for_category(a1, b1, c1)),\n",
    "                            args=(que_1, tokens[0].lower(),\n",
    "                                  seco_category, prim_category))\n",
    "                que_2 = queue.Queue()\n",
    "                t2 = Thread(target=lambda q2, a2, b2: q2.put(\n",
    "                            check_for_did_you_mean(a2, b2)),\n",
    "                            args=(que_2, tokens[0].lower(), tags_2))\n",
    "                que_3 = queue.Queue()\n",
    "                t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                            check_exact_skill_match(a3, b3)),\n",
    "                            args=(que_3, tokens[0].lower(), all_items))\n",
    "                que_4 = queue.Queue()\n",
    "                t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                            check_for_market_place(a4, b4)),\n",
    "                            args=(que_4, tokens[1].lower(), market_place))\n",
    "                t1.start()\n",
    "                t2.start()\n",
    "                t3.start()\n",
    "                t4.start()\n",
    "                t1.join()\n",
    "                t2.join()\n",
    "                t3.join()\n",
    "                t4.join()\n",
    "                scm, pcm = que_1.get()\n",
    "                if (0 != scm):\n",
    "                    temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"secondaryCategory\"] = scm\n",
    "                if (0 != pcm):\n",
    "                    temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"primaryCategory\"] = pcm\n",
    "                dym_val = que_2.get()\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                skill_match, associated_tags = que_3.get()\n",
    "                if (1 == skill_match):\n",
    "                    temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                    temp_dict[\"skillName\"] = tokens[0].lower()\n",
    "                market_place_flag = que_4.get()\n",
    "                if (0 != market_place_flag):\n",
    "                    temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                    temp_dict[\"marketPlace\"] = market_place_flag\n",
    "                two_words_input_flag = 1\n",
    "\n",
    "        # example: Training Java\n",
    "        else:\n",
    "            if (1 == lo_type_found):\n",
    "                # check for token 0 for activity level\n",
    "\n",
    "                que_1 = queue.Queue()\n",
    "                t1 = Thread(target=lambda q1, a1, b1, c1: q1.put(\n",
    "                            check_for_category(a1, b1, c1)),\n",
    "                            args=(que_1, tokens[1].lower(),\n",
    "                                  seco_category, prim_category))\n",
    "                que_2 = queue.Queue()\n",
    "                t2 = Thread(target=lambda q2, a2, b2: q2.put(\n",
    "                            check_for_did_you_mean(a2, b2)),\n",
    "                            args=(que_2, tokens[1].lower(), tags_2))\n",
    "                que_3 = queue.Queue()\n",
    "                t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                            check_exact_skill_match(a3, b3)),\n",
    "                            args=(que_3, tokens[1].lower(), all_items))\n",
    "                que_4 = queue.Queue()\n",
    "                t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                            check_for_market_place(a4, b4)),\n",
    "                            args=(que_4, tokens[1].lower(), market_place))\n",
    "                t1.start()\n",
    "                t2.start()\n",
    "                t3.start()\n",
    "                t4.start()\n",
    "                t1.join()\n",
    "                t2.join()\n",
    "                t3.join()\n",
    "                t4.join()\n",
    "                scm, pcm = que_1.get()\n",
    "                if (0 != scm):\n",
    "                    temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"secondaryCategory\"] = scm\n",
    "                if (0 != pcm):\n",
    "                    temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"primaryCategory\"] = pcm\n",
    "                dym_val = que_2.get()\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                skill_match, associated_tags = que_3.get()\n",
    "                if (1 == skill_match):\n",
    "                    temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                    temp_dict[\"skillName\"] = tokens[1].lower()\n",
    "                market_place_flag = que_4.get()\n",
    "                if (0 != market_place_flag):\n",
    "                    temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                    temp_dict[\"marketPlace\"] = market_place_flag\n",
    "                two_words_input_flag = 1\n",
    "    ##----------------------------------------------##\n",
    "\n",
    "    ##-- example: Advanced Java --------------------##\n",
    "    ##-- example: Python Beginner ------------------##\n",
    "    if (0 == two_words_input_flag):\n",
    "        #print (\"CHK -2b\")\n",
    "        for i in range(0, len(proficiency_level)):\n",
    "            if (tokens[0].lower() == proficiency_level[i].lower()):\n",
    "                temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "                temp_dict[\"userProficiency_search\"] = proficiency_level[i].\\\n",
    "                    lower()\n",
    "                temp_dict[\"phrase\"] = tokens[1].lower()\n",
    "                temp_dict[\"userSearchTags\"] = tokens[1].lower().split(\" \")\n",
    "                dym_val = check_for_did_you_mean(tokens[1].lower(), tags_2)\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                    que_1 = queue.Queue()\n",
    "                    t1 = Thread(\n",
    "                        target=lambda q1, a1, b1: q1.put(\n",
    "                            check_exact_skill_match(\n",
    "                                a1, b1)), args=(\n",
    "                            que_1, temp_dict[\"userSearchTags\"], all_items))\n",
    "                    que_2 = queue.Queue()\n",
    "                    t2 = Thread(target=lambda q2, a2, b2, c2: q2.put(\n",
    "                                check_for_category(a2, b2, c2)),\n",
    "                                args=(que_2, temp_dict[\"userSearchTags\"],\n",
    "                                      seco_category, prim_category))\n",
    "                    t1.start()\n",
    "                    t2.start()\n",
    "                    t1.join()\n",
    "                    t2.join()\n",
    "                    skill_match, associated_tags = que_1.get()\n",
    "                    if (1 == skill_match):\n",
    "                        temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                        tag_item = temp_dict[\"userSearchTags\"]\n",
    "                        if (isinstance(tag_item, list)):\n",
    "                            tag_item_str = \"\".join(tag_item)\n",
    "                            temp_dict[\"skillName\"] = tag_item_str\n",
    "                        else:\n",
    "                            temp_dict[\"skillName\"] = tag_item\n",
    "                    scm, pcm = que_2.get()\n",
    "                    if (0 != scm):\n",
    "                        temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"secondaryCategory\"] = scm\n",
    "                    if (0 != pcm):\n",
    "                        temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"primaryCategory\"] = pcm\n",
    "                two_words_input_flag = 1\n",
    "                break\n",
    "            if (tokens[1].lower() == proficiency_level[i].lower()):\n",
    "                temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "                temp_dict[\"userProficiency_search\"] = proficiency_level[i].lower()\n",
    "                temp_dict[\"phrase\"] = tokens[0].lower()\n",
    "                temp_dict[\"userSearchTags\"] = tokens[0].lower().split(\" \")\n",
    "                dym_val = check_for_did_you_mean(tokens[0].lower(), tags_2)\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                    que_1 = queue.Queue()\n",
    "                    t1 = Thread(\n",
    "                        target=lambda q1, a1, b1: q1.put(\n",
    "                            check_exact_skill_match(\n",
    "                                a1, b1)), args=(\n",
    "                            que_1, temp_dict[\"userSearchTags\"], all_items))\n",
    "                    que_2 = queue.Queue()\n",
    "                    t2 = Thread(target=lambda q2, a2, b2, c2: q2.put(\n",
    "                                check_for_category(a2, b2, c2)),\n",
    "                                args=(que_2, temp_dict[\"userSearchTags\"],\n",
    "                                      seco_category, prim_category))\n",
    "                    t1.start()\n",
    "                    t2.start()\n",
    "                    t1.join()\n",
    "                    t2.join()\n",
    "                    skill_match, associated_tags = que_1.get()\n",
    "                    if (1 == skill_match):\n",
    "                        temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                        tag_item = temp_dict[\"userSearchTags\"]\n",
    "                        if (isinstance(tag_item, list)):\n",
    "                            tag_item_str = \"\".join(tag_item)\n",
    "                            temp_dict[\"skillName\"] = tag_item_str\n",
    "                        else:\n",
    "                            temp_dict[\"skillName\"] = tag_item\n",
    "                    scm, pcm = que_2.get()\n",
    "                    if (0 != scm):\n",
    "                        temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"secondaryCategory\"] = scm\n",
    "                    if (0 != pcm):\n",
    "                        temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"primaryCategory\"] = pcm\n",
    "                two_words_input_flag = 1\n",
    "                break\n",
    "    ##--------------------------------------------------##\n",
    "\n",
    "    # example: Python Coaching --> Delivery Mode\n",
    "    # example: Azure Hackathons --> Delivery Mode\n",
    "    # example: Python Brainbench --> Market Place\n",
    "    # example: Java Udemy --> Market Place\n",
    "    # example: Webscrape C++ --> Market Place\n",
    "    ##---- Developed by CDB-AIA-DS | Arpan Ghose (626636) ----################\n",
    "    if (0 == two_words_input_flag):\n",
    "        #print (\"CHK -2b_2\")\n",
    "        for i in range(0, len(delivery_mode)):\n",
    "            if (tokens[0].lower() == delivery_mode[i].lower()):\n",
    "                temp_dict[\"deliveryModeFlag\"] = \"yes\"\n",
    "                temp_dict[\"deliveryMode\"] = delivery_mode[i].lower()\n",
    "                temp_dict[\"phrase\"] = tokens[1].lower()\n",
    "                temp_dict[\"userSearchTags\"] = tokens[1].lower().split(\" \")\n",
    "                dym_val = check_for_did_you_mean(tokens[1].lower(), tags_2)\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                    que_1 = queue.Queue()\n",
    "                    t1 = Thread(\n",
    "                        target=lambda q1, a1, b1: q1.put(\n",
    "                            check_exact_skill_match(\n",
    "                                a1, b1)), args=(\n",
    "                            que_1, temp_dict[\"userSearchTags\"], all_items))\n",
    "                    que_2 = queue.Queue()\n",
    "                    t2 = Thread(target=lambda q2, a2, b2, c2: q2.put(\n",
    "                                check_for_category(a2, b2, c2)),\n",
    "                                args=(que_2, temp_dict[\"userSearchTags\"],\n",
    "                                      seco_category, prim_category))\n",
    "                    que_3 = queue.Queue()\n",
    "                    t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                                check_for_market_place(a3, b3)),\n",
    "                                args=(que_3, temp_dict[\"userSearchTags\"],\n",
    "                                      market_place))\n",
    "                    t1.start()\n",
    "                    t2.start()\n",
    "                    t3.start()\n",
    "                    t1.join()\n",
    "                    t2.join()\n",
    "                    t3.join()\n",
    "                    skill_match, associated_tags = que_1.get()\n",
    "                    if (1 == skill_match):\n",
    "                        temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                        tag_item = temp_dict[\"userSearchTags\"]\n",
    "                        if (isinstance(tag_item, list)):\n",
    "                            tag_item_str = \"\".join(tag_item)\n",
    "                            temp_dict[\"skillName\"] = tag_item_str\n",
    "                        else:\n",
    "                            temp_dict[\"skillName\"] = tag_item\n",
    "                    scm, pcm = que_2.get()\n",
    "                    if (0 != scm):\n",
    "                        temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"secondaryCategory\"] = scm\n",
    "                    if (0 != pcm):\n",
    "                        temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"primaryCategory\"] = pcm\n",
    "                    # Wrong Input: <Delivery Mode> <Market Place>\n",
    "                    # Coaching Udemy\n",
    "                    market_place_flag = que_3.get()\n",
    "                    if (0 != market_place_flag):\n",
    "                        temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                        temp_dict[\"marketPlace\"] = market_place_flag\n",
    "                        temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                two_words_input_flag = 1\n",
    "                break\n",
    "            if (tokens[1].lower() == delivery_mode[i].lower()):\n",
    "                #print (tokens[1].lower())\n",
    "                temp_dict[\"deliveryModeFlag\"] = \"yes\"\n",
    "                temp_dict[\"deliveryMode\"] = delivery_mode[i].lower()\n",
    "                temp_dict[\"phrase\"] = tokens[0].lower()\n",
    "                temp_dict[\"userSearchTags\"] = tokens[0].lower().split(\" \")\n",
    "                dym_val = check_for_did_you_mean(tokens[0].lower(), tags_2)\n",
    "                if (None is not dym_val):\n",
    "                    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                    temp_dict[\"didYouMean\"] = dym_val.capitalize()\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                    que_1 = queue.Queue()\n",
    "                    t1 = Thread(\n",
    "                        target=lambda q1, a1, b1: q1.put(\n",
    "                            check_exact_skill_match(\n",
    "                                a1, b1)), args=(\n",
    "                            que_1, temp_dict[\"userSearchTags\"], all_items))\n",
    "                    que_2 = queue.Queue()\n",
    "                    t2 = Thread(target=lambda q2, a2, b2, c2: q2.put(\n",
    "                                check_for_category(a2, b2, c2)),\n",
    "                                args=(que_2, temp_dict[\"userSearchTags\"],\n",
    "                                      seco_category, prim_category))\n",
    "                    que_3 = queue.Queue()\n",
    "                    t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                                check_for_market_place(a3, b3)),\n",
    "                                args=(que_3, temp_dict[\"userSearchTags\"],\n",
    "                                      market_place))\n",
    "                    t1.start()\n",
    "                    t2.start()\n",
    "                    t3.start()\n",
    "                    t1.join()\n",
    "                    t2.join()\n",
    "                    t3.join()\n",
    "                    skill_match, associated_tags = que_1.get()\n",
    "                    if (1 == skill_match):\n",
    "                        temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                        tag_item = temp_dict[\"userSearchTags\"]\n",
    "                        if (isinstance(tag_item, list)):\n",
    "                            tag_item_str = \"\".join(tag_item)\n",
    "                            temp_dict[\"skillName\"] = tag_item_str\n",
    "                        else:\n",
    "                            temp_dict[\"skillName\"] = tag_item\n",
    "                    scm, pcm = que_2.get()\n",
    "                    if (0 != scm):\n",
    "                        temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"secondaryCategory\"] = scm\n",
    "                    if (0 != pcm):\n",
    "                        temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"primaryCategory\"] = pcm\n",
    "                    market_place_flag = que_3.get()\n",
    "                    if (0 != market_place_flag):\n",
    "                        temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "                        temp_dict[\"marketPlace\"] = market_place_flag\n",
    "                        temp_dict[\"userSearchTags\"] = \"no\"\n",
    "                two_words_input_flag = 1\n",
    "                break\n",
    "\n",
    "    # example input: Oracle Learning\n",
    "    # example input: Python Game\n",
    "    # hence no need to check for check_exact_skill_match, because it should\n",
    "    # have done before before coming to this point\n",
    "    if (0 == two_words_input_flag):\n",
    "        #print (\"CHK -2c\")\n",
    "\n",
    "        tokens_str = \" \".join(tokens)\n",
    "        #print (\"tokens_str: [%s]\" %tokens_str)\n",
    "        temp_dict[\"userSearchTags\"] = \"no\"\n",
    "        temp_dict[\"didYouMean\"] = \"no\"\n",
    "\n",
    "        que_1 = queue.Queue()\n",
    "        t1 = Thread(target=lambda q1, a1, b1: q1.put(\n",
    "            handle_nlp_extracted_phrase(a1, b1)),\n",
    "            args=(que_1, tokens_str.lower(), tags_2))\n",
    "        que_2 = queue.Queue()\n",
    "        t2 = Thread(target=lambda q2, a2, b2: q2.put(\n",
    "            check_for_did_you_mean(a2, b2)),\n",
    "            args=(que_2, tokens_str.lower(), tags_2))\n",
    "\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "\n",
    "        associated_tags = que_1.get()\n",
    "        if (0 != len(associated_tags)):\n",
    "            temp_dict[\"userSearchTags\"] = associated_tags\n",
    "        #print (\"tags: \", temp_dict[\"userSearchTags\"])\n",
    "        if (\"no\" == temp_dict[\"userSearchTags\"]):\n",
    "            temp_dict[\"userSearchTags\"] = tokens_str.lower().split(\" \")\n",
    "        dym_val = que_2.get()\n",
    "        #print (\"dym_val: [%s]\" %dym_val)\n",
    "        if (None is not dym_val):\n",
    "            temp_dict[\"didYouMean\"] = string.capwords(dym_val)\n",
    "        else:\n",
    "            temp_dict[\"didYouMean\"] = \"no\"\n",
    "            scm, pcm = check_for_category(tokens_str.lower(),\n",
    "                                          seco_category, prim_category)\n",
    "            if (0 != scm):\n",
    "                temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                temp_dict[\"secondaryCategory\"] = scm\n",
    "            if (0 != pcm):\n",
    "                temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                temp_dict[\"primaryCategory\"] = pcm\n",
    "        temp_dict[\"phrase\"] = tokens_str.lower()\n",
    "        temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "        que_3 = queue.Queue()\n",
    "        t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                    check_exact_skill_match(a3, b3)),\n",
    "                    args=(que_3, \"\".join(temp_dict[\"userSearchTags\"]),\n",
    "                          all_items))\n",
    "        que_4 = queue.Queue()\n",
    "        t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                    check_exact_skill_code(a4, b4)),\n",
    "                    args=(que_4, \"\".join(temp_dict[\"userSearchTags\"]),\n",
    "                          all_items))\n",
    "        que_5 = queue.Queue()\n",
    "        t5 = Thread(target=lambda q5, a5, b5, c5: q5.put(\n",
    "                    check_for_category(a5, b5, c5)),\n",
    "                    args=(que_5, \"\".join(temp_dict[\"userSearchTags\"]),\n",
    "                          seco_category, prim_category))\n",
    "        t3.start()\n",
    "        t4.start()\n",
    "        t5.start()\n",
    "        t3.join()\n",
    "        t4.join()\n",
    "        t5.join()\n",
    "        skill_match, skill_name_tags = que_3.get()\n",
    "        skill_code_match_flag, skill_code_tags = que_4.get()\n",
    "        if ((1 == skill_match) and (0 == skill_code_match_flag)):\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "            temp_dict[\"skillName\"] = temp_dict[\"userSearchTags\"]\n",
    "            temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "        if ((1 == skill_code_match_flag) and (0 == skill_match)):\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "            temp_dict[\"skillCodeMatchFlag\"] = \"yes\"\n",
    "            temp_dict[\"skillCode\"] = temp_dict[\"userSearchTags\"]\n",
    "        scm, pcm = que_5.get()\n",
    "        if (0 != scm):\n",
    "            temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "            temp_dict[\"secondaryCategory\"] = scm\n",
    "        if (0 != pcm):\n",
    "            temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "            temp_dict[\"primaryCategory\"] = pcm\n",
    "\n",
    "        if ((0 == skill_match) or (0 == skill_code_match_flag)):\n",
    "            tag_list = temp_dict[\"userSearchTags\"]\n",
    "            for i in range(0, len(tag_list)):\n",
    "                skill_match_2, skill_name_tags_2 = check_exact_skill_match(\n",
    "                    tag_list[i], all_items)\n",
    "                if (1 == skill_match_2):\n",
    "                    temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                    temp_dict[\"skillName\"] = skill_name_tags_2\n",
    "                    temp_dict[\"userSearchTags\"] = skill_name_tags_2\n",
    "                    break\n",
    "        two_words_input_flag = 1\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: process_whole_match_activity_label_or_lo_type\n",
    "# This function is used to check for activity label name and learning object\n",
    "# type in the user input.\n",
    "\n",
    "def process_whole_match_activity_label_or_lo_type(\n",
    "        tokens_str,\n",
    "        temp_dict,\n",
    "        keywords_list):\n",
    "    print(\"Function: process_whole_match_activity_label_or_lo_type\")\n",
    "    #print (\"tokens_str: [%s]\" %tokens_str)\n",
    "    whole_match_activity_label_or_lo_found = 0\n",
    "    activity_label_found = 0\n",
    "    lo_found = 0\n",
    "\n",
    "    # check for lo_type\n",
    "    if (0 == whole_match_activity_label_or_lo_found):\n",
    "        for j in range(0, len(keywords_list)):\n",
    "            if ((tokens_str.lower() == keywords_list['value'][j].lower()) or (\n",
    "                    tokens_str[0:-1].lower() == keywords_list['value'][j].lower())):\n",
    "                print(\"Full Match - LO type\")\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                temp_dict[\"learningObject\"] = keywords_list['key'][j].lower()\n",
    "                lo_found = 1\n",
    "                print(temp_dict)\n",
    "                break\n",
    "\n",
    "    if (1 == lo_found):\n",
    "        whole_match_activity_label_or_lo_found = 1\n",
    "    return whole_match_activity_label_or_lo_found\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: process_input_having_market_place\n",
    "# This function is used to check for the  market place name in the user's\n",
    "# search query.\n",
    "\n",
    "\n",
    "def process_input_having_market_place(\n",
    "        sample_3,\n",
    "        temp_dict,\n",
    "        market_place,\n",
    "        proficiency_level,\n",
    "        vowel_list):\n",
    "\n",
    "    print(\"Function: [process_input_having_market_place]\")\n",
    "    #print (temp_dict)\n",
    "    #print (sample_3)\n",
    "    chk_flag = 0\n",
    "    for i in range(0, len(market_place)):\n",
    "        if (market_place[i].lower() in sample_3):\n",
    "            print(\"Found: Input having Market Place\")\n",
    "            sample_3 = sample_3.replace(market_place[i].lower(), \"\")\n",
    "            temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "            temp_dict[\"marketPlace\"] = market_place[i]\n",
    "            chk_flag = 1\n",
    "            break\n",
    "    if (1 == chk_flag):\n",
    "        #print (temp_dict[\"flagProficiency\"])\n",
    "        if (temp_dict[\"flagProficiency\"] == \"no\"):\n",
    "            pl_found_flag = 0\n",
    "            for loop_cnt in range(0, len(proficiency_level)):\n",
    "                if (proficiency_level[loop_cnt].lower() in sample_3):\n",
    "                    sample_3 = sample_3.replace(proficiency_level[loop_cnt].\n",
    "                                                lower(), \"\")\n",
    "                    temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "                    temp_dict[\"userProficiency_search\"] = \\\n",
    "                        proficiency_level[loop_cnt].lower()\n",
    "                    pl_found_flag = 1\n",
    "                    break\n",
    "            if (0 == pl_found_flag):\n",
    "                print(\"flagProficiency is not found\")\n",
    "                temp_dict[\"flagProficiency\"] = \"no\"\n",
    "        np_extractor_object = Noun_Phrase_Extraction(sample_3)\n",
    "        np_result = np_extractor_object.extract()\n",
    "        temp_str = \" \".join(np_result)\n",
    "        #temp_str_tokens = word_tokenize(temp_str)\n",
    "        temp_str_tokens = temp_str.split(\" \")\n",
    "        np_result_2 = [item for item in temp_str_tokens if item not in\n",
    "                       vowel_list]\n",
    "        temp_str_2 = \" \".join(np_result_2)\n",
    "        temp_dict[\"phrase\"] = temp_str_2\n",
    "\n",
    "    return chk_flag, sample_3\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: process_input_having_delivery_mode\n",
    "# This function is used to check for the delivery mode name in the user\n",
    "# search input query.\n",
    "\n",
    "\n",
    "def process_input_having_delivery_mode(\n",
    "        search_query_cp,\n",
    "        temp_dict,\n",
    "        delivery_mode,\n",
    "        proficiency_level,\n",
    "        vowel_list):\n",
    "\n",
    "    print(\"Function: [process_input_having_delivery_mode]\")\n",
    "    chk_flag = 0\n",
    "    for i in range(0, len(delivery_mode)):\n",
    "        if (delivery_mode[i].lower() in search_query_cp):\n",
    "            print(\"Found: Input having Delivery Mode\")\n",
    "            search_query_cp = search_query_cp.replace(\n",
    "                delivery_mode[i].lower(), \"\")\n",
    "            temp_dict[\"deliveryModeFlag\"] = \"yes\"\n",
    "            temp_dict[\"deliveryMode\"] = delivery_mode[i].lower()\n",
    "            chk_flag = 1\n",
    "            break\n",
    "    if (1 == chk_flag):\n",
    "        if (temp_dict[\"flagProficiency\"] == \"no\"):\n",
    "            pl_found_flag = 0\n",
    "            for loop_cnt in range(0, len(proficiency_level)):\n",
    "                if (proficiency_level[loop_cnt].lower() in search_query_cp):\n",
    "                    search_query_cp = search_query_cp.replace(\n",
    "                        proficiency_level[loop_cnt]. lower(), \"\")\n",
    "                    temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "                    temp_dict[\"userProficiency_search\"] = proficiency_level[loop_cnt].lower(\n",
    "                    )\n",
    "                    pl_found_flag = 1\n",
    "                    break\n",
    "            if (0 == pl_found_flag):\n",
    "                temp_dict[\"flagProficiency\"] = \"no\"\n",
    "\n",
    "        np_extractor_object = Noun_Phrase_Extraction(search_query_cp)\n",
    "        np_result = np_extractor_object.extract()\n",
    "        temp_str = \" \".join(np_result)\n",
    "        #temp_str_tokens = word_tokenize(temp_str)\n",
    "        temp_str_tokens = temp_str.split(\" \")\n",
    "        np_result_2 = [item for item in temp_str_tokens if item not in\n",
    "                       vowel_list]\n",
    "        temp_str_2 = \" \".join(np_result_2)\n",
    "        temp_dict[\"phrase\"] = temp_str_2\n",
    "\n",
    "    return chk_flag, search_query_cp\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: process_input_having_keywords\n",
    "# This function is a supporting function to check for activity label name and\n",
    "# learning object type.\n",
    "\n",
    "\n",
    "def process_input_having_keywords(\n",
    "    search_query_lwr,\n",
    "    temp_dict,\n",
    "    keywords_list,\n",
    "    seco_category,\n",
    "    prim_category,\n",
    "    proficiency_level,\n",
    "        vowel_list):\n",
    "\n",
    "    #print (\"CHK -3a\")\n",
    "    chk_flag_1 = 0\n",
    "    chk_flag_2 = 0\n",
    "    chk_flag = 0\n",
    "\n",
    "    local_stopwords = [\"availability\"]\n",
    "    if (local_stopwords[0] in search_query_lwr):\n",
    "        search_query_lwr = search_query_lwr.replace(local_stopwords[0], \"\")\n",
    "    search_query_cp = copy.copy(search_query_lwr)\n",
    "    search_query_lwr_tokens = search_query_lwr.split()\n",
    "    #print (\"search_query_lwr_tokens: \", search_query_lwr_tokens)\n",
    "\n",
    "    lo_type_list = []\n",
    "    if (0 == chk_flag_2):\n",
    "        for j in range(0, len(keywords_list)):\n",
    "            plural_str = keywords_list['value'][j].lower() + \"s\"\n",
    "            if (plural_str in search_query_lwr):\n",
    "                #print (\"CHK -3aa-lo_type_1\")\n",
    "                search_query_lwr = search_query_lwr.replace(plural_str, \"\")\n",
    "                chk_flag_2 = 1\n",
    "\n",
    "            if ((keywords_list['value'][j].lower()) in search_query_lwr):\n",
    "                #print (\"CHK -3ab-lo_type_1\")\n",
    "                search_query_lwr = search_query_lwr.replace(\n",
    "                    keywords_list['value'][j].lower(), \"\")\n",
    "                chk_flag_2 = 1\n",
    "\n",
    "            if (1 == chk_flag_2):\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                lo_type_list.append(keywords_list['value'][j].lower())\n",
    "                chk_flag_2 = 0\n",
    "                break\n",
    "\n",
    "    if (\"no\" == temp_dict[\"learningObjectFlag\"]):\n",
    "        search_query_cp = search_query_cp.replace(\n",
    "            \"instructor led training\", \"\")\n",
    "\n",
    "        for j in range(0, len(keywords_list)):\n",
    "            plural_str = keywords_list['value'][j].lower() + \"s\"\n",
    "            if (plural_str in search_query_cp):\n",
    "                #print (\"CHK -3aa-lo_type_2\")\n",
    "                search_query_lwr = search_query_lwr.replace(plural_str, \"\")\n",
    "                chk_flag_2 = 1\n",
    "            if (keywords_list['value'][j].lower() in search_query_cp):\n",
    "                #print (\"CHK -3ab-lo_type_2\")\n",
    "                search_query_lwr = search_query_lwr.replace(\n",
    "                    keywords_list['value'][j].lower(), \"\")\n",
    "                chk_flag_2 = 1\n",
    "            if (1 == chk_flag_2):\n",
    "                temp_dict[\"learningObjectFlag\"] = \"yes\"\n",
    "                lo_type_list.append(keywords_list['value'][j].lower())\n",
    "                chk_flag_2 = 0\n",
    "                break\n",
    "    #temp_dict[\"learningObject\"] = lo_type_list\n",
    "    if (1 == len(lo_type_list)):\n",
    "        lo_type_list_str = \"\".join(lo_type_list)\n",
    "        temp_dict[\"learningObject\"] = lo_type_list_str\n",
    "    else:\n",
    "        lo_type_list_str = \", \".join(lo_type_list)\n",
    "        temp_dict[\"learningObject\"] = lo_type_list_str\n",
    "        \n",
    "    if (\"yes\" == temp_dict[\"learningObjectFlag\"]):\n",
    "        chk_flag = 1\n",
    "        #print (\"search_query_lwr: [%s]\" %search_query_lwr)\n",
    "\n",
    "        pl_found_flag = 0\n",
    "        for loop_cnt in range(0, len(proficiency_level)):\n",
    "            if (proficiency_level[loop_cnt].lower() in search_query_lwr):\n",
    "                search_query_lwr = search_query_lwr.replace(\n",
    "                    proficiency_level[loop_cnt]. lower(), \"\")\n",
    "                temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "                temp_dict[\"userProficiency_search\"] = proficiency_level[loop_cnt].lower()\n",
    "                pl_found_flag = 1\n",
    "                #print (\"PL found\")\n",
    "                break\n",
    "        if (0 == pl_found_flag):\n",
    "            #print (\"PL is not found\")\n",
    "            temp_dict[\"flagProficiency\"] = \"no\"\n",
    "\n",
    "        #print (\"search_query_lwr becomes: [%s]\" %search_query_lwr.strip())\n",
    "        scm, pcm = check_for_category(search_query_lwr.strip(),\n",
    "                                      seco_category, prim_category)\n",
    "        if (0 != scm):\n",
    "            temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "            temp_dict[\"secondaryCategory\"] = scm\n",
    "        if (0 != pcm):\n",
    "            temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "            temp_dict[\"primaryCategory\"] = pcm\n",
    "\n",
    "        if ((0 == scm) and (0 == pcm)):\n",
    "            search_query_lwr_tokens = search_query_lwr.split()\n",
    "            #print (search_query_lwr_tokens)\n",
    "            search_query_lwr_tokens_length = len(search_query_lwr_tokens)\n",
    "\n",
    "            for j in range(0, len(seco_category)):\n",
    "                temp_item = seco_category[j].lower()\n",
    "                temp_item_tokens = temp_item.split()\n",
    "                first_seco_match = 0\n",
    "                for lc_2 in range(0, len(search_query_lwr_tokens)):\n",
    "                    if (search_query_lwr_tokens[lc_2] == temp_item_tokens[0]):\n",
    "                        first_seco_match = 1\n",
    "                        break\n",
    "                if ((1 == first_seco_match) and (\n",
    "                        temp_item in search_query_lwr)):\n",
    "                    temp_dict[\"secondaryCategory\"] = temp_item\n",
    "                    break\n",
    "\n",
    "            for k in range(0, len(prim_category)):\n",
    "                temp_item = prim_category[k].lower()\n",
    "                temp_item_tokens = temp_item.split()\n",
    "                first_prim_match = 0\n",
    "                for lc_3 in range(0, len(search_query_lwr_tokens)):\n",
    "                    if (search_query_lwr_tokens[lc_3] == temp_item_tokens[0]):\n",
    "                        first_prim_match = 1\n",
    "                        break\n",
    "                if ((1 == first_prim_match) and (\n",
    "                        temp_item in search_query_lwr)):\n",
    "                    temp_dict[\"primaryCategory\"] = temp_item\n",
    "                    break\n",
    "\n",
    "        np_extractor_object = Noun_Phrase_Extraction(search_query_lwr)\n",
    "        np_result = np_extractor_object.extract()\n",
    "        #print (\"np_result becomes: \", np_result)\n",
    "        temp_str = \" \".join(np_result)\n",
    "        #temp_str_tokens = word_tokenize(temp_str)\n",
    "        temp_str_tokens = temp_str.split(\" \")\n",
    "        np_result_2 = [item for item in temp_str_tokens if item not in\n",
    "                       vowel_list]\n",
    "        temp_str_2 = \" \".join(np_result_2)\n",
    "        temp_dict[\"phrase\"] = temp_str_2\n",
    "\n",
    "    return chk_flag, search_query_lwr\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_exact_title_match\n",
    "# This function is used to check whether the user input is exactly matches\n",
    "# with the title name or not. This function takes three parameters - user's\n",
    "# search input query, tag josn's content, all tag values from TAG JSON file.\n",
    "\n",
    "\n",
    "def check_exact_title_match(input_query, all_items, tags):\n",
    "\n",
    "    user_input = input_query.lower()\n",
    "    print(\"User Input: [%s]\" % user_input)\n",
    "\n",
    "    req_tags = 0\n",
    "    title_match_flag = 0\n",
    "\n",
    "    titles = list(map(itemgetter(\"ActivityName\"), all_items))\n",
    "    #print (len(titles))\n",
    "\n",
    "    titles_2 = []\n",
    "    for i in range(0, len(titles)):\n",
    "        temp_item = titles[i]\n",
    "        if (isinstance(temp_item, str)):\n",
    "            temp_item = temp_item.lower()\n",
    "            titles_2.append(temp_item)\n",
    "        if (isinstance(temp_item, float)):\n",
    "            temp_item = int(temp_item)\n",
    "            titles_2.append(str(temp_item))\n",
    "    #print (len(titles_2))\n",
    "    #print (titles_2)\n",
    "\n",
    "    for i in range(0, len(titles_2)):\n",
    "        if ((input_query == titles_2[i]) or (user_input == titles_2[i])):\n",
    "            title_match_flag = 1\n",
    "            req_tags = tags[i].lower().split(\", \")\n",
    "\n",
    "    return title_match_flag, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_exact_title_code\n",
    "# This function is used to check whether the user input is exactly matches\n",
    "# with the title code or not. This function takes three parameters - user's\n",
    "# search input query, tag josn's content, all tag values from TAG JSON file.\n",
    "\n",
    "\n",
    "def check_exact_title_code(input_query, all_items, tags):\n",
    "    req_tags = 0\n",
    "    title_code_match = 0\n",
    "    title_codes = list(map(itemgetter(\"ActivityCode\"), all_items))\n",
    "    #print (len(title_codes))\n",
    "    ### 23-06-2021 Adding Logic to work on Null Activity Code\n",
    "    title_codes_2 = []\n",
    "    for i in range(0, len(title_codes)):\n",
    "        temp_item = title_codes[i]\n",
    "        if (isinstance(temp_item, str)):\n",
    "            temp_item = temp_item.lower()\n",
    "            title_codes_2.append(temp_item)\n",
    "        elif (isinstance(temp_item, float)):\n",
    "            temp_item = int(temp_item)\n",
    "            title_codes_2.append(str(temp_item))\n",
    "        elif temp_item is None:\n",
    "            title_codes_2.append(temp_item)\n",
    "    #print (len(title_codes_2))\n",
    "    #print (\"Retrieved title_codes_2: \", title_codes_2)\n",
    "\n",
    "    if (isinstance(input_query, str)):\n",
    "        temp_item = input_query.lower()\n",
    "    #print (\"temp_item: [%s]\" %temp_item)\n",
    "\n",
    "    for i in range(0, len(title_codes_2)):\n",
    "        if (temp_item == title_codes_2[i]):\n",
    "            title_code_match = 1\n",
    "            req_tags = tags[i].lower().split(\", \")\n",
    "\n",
    "    #print (req_tags)\n",
    "    return title_code_match, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_for_skill_match\n",
    "# This function is used to check for skill name from the customized user input.\n",
    "\n",
    "\n",
    "def check_for_skill_match(query_str, all_items):\n",
    "    print(\"query_str in check_for_skill_match: [%s]\" % query_str)\n",
    "    query_str_list = query_str.split(\" \")\n",
    "    #print (query_str_list)\n",
    "    req_tags = 0\n",
    "    skill_match_flag = 0\n",
    "\n",
    "    all_skills = list(map(itemgetter(\"SkillName\"), all_items))\n",
    "    #print (len(all_skills))\n",
    "    Not_none_values = filter(None.__ne__, all_skills)\n",
    "    skills = list(Not_none_values)\n",
    "    #print (\"Total length of skills: \", len(skills))\n",
    "\n",
    "    skills_2 = []\n",
    "    for i in range(0, len(skills)):\n",
    "        if (\"~\" in skills[i]):\n",
    "            #print (skills[i])\n",
    "            item_list = ''.join(skills[i]).split(' ~ ')\n",
    "            #print (item_list)\n",
    "            item_list_2 = []\n",
    "            for j in range(0, len(item_list)):\n",
    "                temp_item_1 = item_list[j]\n",
    "                if (isinstance(temp_item_1, str)):\n",
    "                    temp_item_1 = temp_item_1.lower()\n",
    "                    item_list_2.append(temp_item_1)\n",
    "                if (isinstance(temp_item_1, float)):\n",
    "                    temp_item_1 = int(temp_item_1)\n",
    "                    item_list_2.append(str(temp_item_1))\n",
    "            skills_2.append(item_list_2)\n",
    "        else:\n",
    "            temp_item_2 = skills[i]\n",
    "            if (isinstance(temp_item_2, str)):\n",
    "                temp_item_2 = temp_item_2.lower()\n",
    "                skills_2.append(temp_item_2)\n",
    "            if (isinstance(temp_item_2, float)):\n",
    "                temp_item = int(temp_item_2)\n",
    "                skills_2.append(str(temp_item_2))\n",
    "\n",
    "    for i in range(0, len(skills_2)):\n",
    "        if (isinstance(skills_2[i], list)):\n",
    "            for j in range(0, len(skills_2[i])):\n",
    "                single_item = skills_2[i][j]\n",
    "                for k in range(0, len(query_str_list)):\n",
    "                    if (single_item == query_str_list[k]):\n",
    "                        req_tags = skills_2[i][j]\n",
    "                        #print (\"req_tags (1): \", req_tags)\n",
    "                        skill_match_flag = 1\n",
    "                        break\n",
    "                if (1 == skill_match_flag):\n",
    "                    break\n",
    "        else:\n",
    "            if (skills_2[i] != \"\"):\n",
    "                for k in range(0, len(query_str_list)):\n",
    "                    if (skills_2[i] == query_str_list[k]):\n",
    "                        req_tags = skills_2[i]\n",
    "                        #print (\"req_tags (2): \", req_tags)\n",
    "                        skill_match_flag = 1\n",
    "                        break\n",
    "    return skill_match_flag, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_exact_skill_match\n",
    "# This function is used to check whether the user input is exactly matches\n",
    "# with the skill name or not. This function takes two parameters - user's\n",
    "# search input query, all tag values from TAG JSON file.\n",
    "\n",
    "\n",
    "def check_exact_skill_match(input_query, all_items):\n",
    "    print(\"input_query in check_exact_skill_match: [%s]\" % input_query)\n",
    "    if (isinstance(input_query, list)):\n",
    "        input_query = \"\".join(input_query)\n",
    "    user_input = input_query.lower()\n",
    "    req_tags = 0\n",
    "    skill_match_flag = 0\n",
    "\n",
    "    all_skills = list(map(itemgetter(\"SkillName\"), all_items))\n",
    "    #print (len(all_skills))\n",
    "    Not_none_values = filter(None.__ne__, all_skills)\n",
    "    skills = list(Not_none_values)\n",
    "    #print (\"Total length of skills: \", len(skills))\n",
    "\n",
    "    skills_2 = []\n",
    "    for i in range(0, len(skills)):\n",
    "        if (\"~\" in skills[i]):\n",
    "            #print (skills[i])\n",
    "            item_list = ''.join(skills[i]).split(' ~ ')\n",
    "            #print (item_list)\n",
    "            item_list_2 = []\n",
    "            for j in range(0, len(item_list)):\n",
    "                temp_item_1 = item_list[j]\n",
    "                if (isinstance(temp_item_1, str)):\n",
    "                    temp_item_1 = temp_item_1.lower()\n",
    "                    item_list_2.append(temp_item_1)\n",
    "                if (isinstance(temp_item_1, float)):\n",
    "                    temp_item_1 = int(temp_item_1)\n",
    "                    item_list_2.append(str(temp_item_1))\n",
    "            skills_2.append(item_list_2)\n",
    "        else:\n",
    "            temp_item_2 = skills[i]\n",
    "            if (isinstance(temp_item_2, str)):\n",
    "                temp_item_2 = temp_item_2.lower()\n",
    "                skills_2.append(temp_item_2)\n",
    "            if (isinstance(temp_item_2, float)):\n",
    "                temp_item = int(temp_item_2)\n",
    "                skills_2.append(str(temp_item_2))\n",
    "\n",
    "    for i in range(0, len(skills_2)):\n",
    "        if (1 == len(skills_2[i]) and (user_input == skills_2[i])):\n",
    "            skill_match_flag = 1\n",
    "            break\n",
    "        else:\n",
    "            for j in range(0, len(skills_2[i])):\n",
    "                if (user_input == skills_2[i][j]):\n",
    "                    skill_match_flag = 1\n",
    "                    break\n",
    "            if (1 == skill_match_flag):\n",
    "                break\n",
    "\n",
    "    if (1 == skill_match_flag):\n",
    "        req_tags = user_input\n",
    "    return skill_match_flag, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_exact_skill_code\n",
    "# This function is used to check whether the user input is exactly matches\n",
    "# with the skill code or not. This function takes two parameters - user's\n",
    "# search input query, all tag values from TAG JSON file.\n",
    "\n",
    "\n",
    "def check_exact_skill_code(input_query, all_items):\n",
    "    input_query_lwr = None\n",
    "    if (isinstance(input_query, str)):\n",
    "        input_query_lwr = input_query.lower()\n",
    "    print(\"input_query_lwr for exact skill_code: [%s]\" % input_query_lwr)\n",
    "\n",
    "    req_tags = 0\n",
    "    skill_code_match = 0\n",
    "    all_skill_codes = list(map(itemgetter(\"SkillCode\"), all_items))\n",
    "    Not_none_values = filter(None.__ne__, all_skill_codes)\n",
    "    skill_codes = list(Not_none_values)\n",
    "    print(\"Total length of skill_codes: \", len(skill_codes))\n",
    "\n",
    "    skill_codes_2 = []\n",
    "    for i in range(0, len(skill_codes)):\n",
    "        if ((None is not skill_codes[i]) and (\"~\" in skill_codes[i])):\n",
    "            #print (skill_codes[i])\n",
    "            item_list = ''.join(skill_codes[i]).split(' ~ ')\n",
    "            #print (item_list)\n",
    "            item_list_2 = []\n",
    "            for j in range(0, len(item_list)):\n",
    "                temp_item_1 = item_list[j]\n",
    "                if (isinstance(temp_item_1, str)):\n",
    "                    temp_item_1 = temp_item_1.lower()\n",
    "                    item_list_2.append(temp_item_1)\n",
    "                if (isinstance(temp_item_1, float)):\n",
    "                    temp_item_1 = int(temp_item_1)\n",
    "                    item_list_2.append(str(temp_item_1))\n",
    "            skill_codes_2.append(item_list_2)\n",
    "        else:\n",
    "            if (None is not skill_codes[i]):\n",
    "                temp_item_2 = skill_codes[i]\n",
    "                if (isinstance(temp_item_2, str)):\n",
    "                    temp_item_2 = temp_item_2.lower()\n",
    "                    skill_codes_2.append(temp_item_2)\n",
    "                if (isinstance(temp_item_2, float)):\n",
    "                    temp_item_2 = int(temp_item_2)\n",
    "                    skill_codes_2.append(str(temp_item_2))\n",
    "    #print (skill_codes_2)\n",
    "\n",
    "    for i in range(0, len(skill_codes_2)):\n",
    "        if ((isinstance(skill_codes_2[i], str)) and\n",
    "                (input_query_lwr == skill_codes_2[i])):\n",
    "            req_item = [\n",
    "                d for d in all_items if d[\"SkillCode\"] == input_query_lwr]\n",
    "            skill_code_match = 1\n",
    "            #print (\"req_item: \", req_item)\n",
    "            #print (len(req_item))\n",
    "            req_tags = list(map(itemgetter(\"SkillName\"), req_item))\n",
    "            req_tags_2 = []\n",
    "            for i in range(0, len(req_tags)):\n",
    "                split_item = req_tags[i].lower().split(\" \")\n",
    "                for j in range(0, len(split_item)):\n",
    "                    req_tags_2.append(split_item[j])\n",
    "            return skill_code_match, req_tags_2\n",
    "        if ((0 == skill_code_match) and (isinstance(skill_codes_2[i], list))):\n",
    "            for j in range(0, len(skill_codes_2[i])):\n",
    "                if (input_query_lwr == skill_codes_2[i][j]):\n",
    "                    #print (\"Skill Code Found\")\n",
    "                    skill_code_match = 1\n",
    "                    break\n",
    "        if (1 == skill_code_match):\n",
    "            for lc_1 in range(0, len(all_items)):\n",
    "                if (input_query_lwr in all_items[lc_1][\"SkillCode\"]):\n",
    "                    #print (\"req_item has been found\")\n",
    "                    req_item = all_items[lc_1]\n",
    "                    #print (req_item[\"skillName\"])\n",
    "                    req_tags = ''.join(req_item[\"SkillName\"]).split(' ~ ')\n",
    "                    req_tags = req_tags[j].lower().split(\" \")\n",
    "                    #print (\"req_tags: \", req_tags)\n",
    "                    return skill_code_match, req_tags\n",
    "\n",
    "    # Default return\n",
    "    return skill_code_match, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: check_title_code\n",
    "# This function is used to check for title code from the customized user\n",
    "# search input query.\n",
    "\n",
    "\n",
    "def check_title_code(phrase_tokens, all_items):\n",
    "    print(\"function: [check_title_code]\")\n",
    "    #print (\"phrase_tokens: [%s]\" %phrase_tokens)\n",
    "    title_code_match = 0\n",
    "    req_tags = 0\n",
    "    temp_item = 0\n",
    "\n",
    "    title_codes = list(map(itemgetter(\"ActivityCode\"), all_items))\n",
    "\n",
    "    title_codes_2 = []\n",
    "    for i in range(0, len(title_codes)):\n",
    "        temp_item = title_codes[i]\n",
    "        if (isinstance(temp_item, str)):\n",
    "            temp_item = temp_item.lower()\n",
    "            title_codes_2.append(temp_item)\n",
    "        if (isinstance(temp_item, float)):\n",
    "            temp_item = int(temp_item)\n",
    "            title_codes_2.append(str(temp_item))\n",
    "    #print (len(title_codes_2))\n",
    "    #print (\"Retrieved title_codes_2: \", title_codes_2)\n",
    "\n",
    "    for i in range(0, len(phrase_tokens)):\n",
    "        temp_item = phrase_tokens[i]\n",
    "        if (isinstance(temp_item, float)):\n",
    "            temp_item = int(temp_item)\n",
    "        #print (\"temp_item: [%s]\" %temp_item)\n",
    "        for j in range(0, len(title_codes_2)):\n",
    "            if (temp_item == title_codes_2[j]):\n",
    "                title_code_match = 1\n",
    "                req_tags = tags[j].lower().split(\", \")\n",
    "    #print (\"temp_item: [%s]\" %temp_item)\n",
    "    return title_code_match, temp_item, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def check_skill_code(phrase_tokens, all_items):\n",
    "    skill_code_match = 0\n",
    "    temp_item = 0\n",
    "    req_tags = 0\n",
    "    all_skill_codes = list(map(itemgetter(\"SkillCode\"), all_items))\n",
    "    Not_none_values = filter(None.__ne__, all_skill_codes)\n",
    "    skill_codes = list(Not_none_values)\n",
    "    #print (\"Total length of skill_codes: \", len(skill_codes))\n",
    "\n",
    "    skill_codes_2 = []\n",
    "    for i in range(0, len(skill_codes)):\n",
    "        if ((None is not skill_codes[i]) and (\"~\" in skill_codes[i])):\n",
    "            #print (skills_codes[i])\n",
    "            item_list = ''.join(skill_codes[i]).split(' ~ ')\n",
    "            #print (item_list)\n",
    "            item_list_2 = []\n",
    "            for j in range(0, len(item_list)):\n",
    "                temp_item_1 = item_list[j]\n",
    "                if (isinstance(temp_item_1, str)):\n",
    "                    temp_item_1 = temp_item_1.lower()\n",
    "                    item_list_2.append(temp_item_1)\n",
    "                if (isinstance(temp_item_1, float)):\n",
    "                    temp_item_1 = int(temp_item_1)\n",
    "                    item_list_2.append(str(temp_item_1))\n",
    "            skill_codes_2.append(item_list_2)\n",
    "        else:\n",
    "            if (None is not skill_codes[i]):\n",
    "                temp_item_2 = skill_codes[i]\n",
    "                if (isinstance(temp_item_2, str)):\n",
    "                    temp_item_2 = temp_item_2.lower()\n",
    "                    skill_codes_2.append(temp_item_2)\n",
    "                if (isinstance(temp_item_2, float)):\n",
    "                    temp_item_2 = int(temp_item_2)\n",
    "                    skill_codes_2.append(str(temp_item_2))\n",
    "    #print (skill_codes_2)\n",
    "\n",
    "    for i in range(0, len(phrase_tokens)):\n",
    "        temp_item = phrase_tokens[i]\n",
    "        #print (\"temp_item=> [%s]\" %temp_item)\n",
    "        for j in range(0, len(skill_codes_2)):\n",
    "            if ((isinstance(skill_codes_2[j], str)) and\n",
    "                    (temp_item == skill_codes_2[j])):\n",
    "                req_item = [\n",
    "                    d for d in all_items if d[\"SkillCode\"] == temp_item]\n",
    "                skill_code_match = 1\n",
    "                #print (\"req_item: \", req_item)\n",
    "                #print (len(req_item))\n",
    "                req_tags = list(map(itemgetter(\"SkillName\"), req_item))\n",
    "                req_tags_2 = []\n",
    "                for i in range(0, len(req_tags)):\n",
    "                    split_item = req_tags[i].lower().split(\" \")\n",
    "                    for j in range(0, len(split_item)):\n",
    "                        req_tags_2.append(split_item[j])\n",
    "                return skill_code_match, temp_item, req_tags_2\n",
    "            if ((0 == skill_code_match) and (\n",
    "                    isinstance(skill_codes_2[j], list))):\n",
    "                for k in range(0, len(skill_codes_2[j])):\n",
    "                    if (temp_item == skill_codes_2[j][k]):\n",
    "                        print(\"Skill Code Found\")\n",
    "                        skill_code_match = 1\n",
    "                        break\n",
    "            if (1 == skill_code_match):\n",
    "                for lc_1 in range(0, len(all_items)):\n",
    "                    if (temp_item in all_items[lc_1][\"SkillCode\"]):\n",
    "                        #print (\"req_item has been found\")\n",
    "                        req_item = all_items[lc_1]\n",
    "                        req_tags = ''.join(req_item[\"SkillName\"]).split(' ~ ')\n",
    "                        req_tags = req_tags[k].lower().split(\" \")\n",
    "                        return skill_code_match, temp_item, req_tags\n",
    "\n",
    "    #print (\"skill_code_match: [%s]\" %skill_code_match)\n",
    "    #print (\"req_tags: \", req_tags)\n",
    "\n",
    "    # default return\n",
    "    return skill_code_match, temp_item, req_tags\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "## Function: process_ui_output\n",
    "# This is the starting function which starts operation with the user input.\n",
    "# This function introduces thread level parallelism to check for exact title\n",
    "# match, exact title code, exact skill match, exact skill code, check for\n",
    "# category, check for market place.\n",
    "# On next level, this function acts in three distict ways for the user input\n",
    "# query - for the input comprised of single word, for input comprised of two\n",
    "# words, for the input comprised of more than two words.\n",
    "\n",
    "\n",
    "def process_ui_output(\n",
    "        ui_output,\n",
    "        keywords_list,\n",
    "        all_items,\n",
    "        tags,\n",
    "        tags_2,\n",
    "        prim_category,\n",
    "        seco_category,\n",
    "        delivery_mode,\n",
    "        market_place,\n",
    "        vowel_list,\n",
    "        proficiency_level):\n",
    "\n",
    "    input_query = ui_output[\"Search_String\"]\n",
    "    input_query = input_query.strip()\n",
    "    print(\"input_query = [%s]\" % input_query)\n",
    "\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"secondaryCategoryFlag\"] = \"no\"\n",
    "    temp_dict[\"primaryCategoryFlag\"] = \"no\"\n",
    "\n",
    "    ##---- check for exact title name -----##\n",
    "    title_match = 0\n",
    "    title_name_tags = 0\n",
    "\n",
    "    ##---- check for exact title code -----##\n",
    "    title_code_match_flag = 0\n",
    "    title_code_tags = 0\n",
    "\n",
    "    ##---- check for exact skill name -----##\n",
    "    skill_match = 0\n",
    "    skill_name_tags = 0\n",
    "\n",
    "    ##---- check for exact skill code -----##\n",
    "    skill_code_match_flag = 0\n",
    "    skill_code_tags = 0\n",
    "\n",
    "    que_1 = queue.Queue()\n",
    "    t1 = Thread(target=lambda q1, a1, b1, c1: q1.put(\n",
    "                check_exact_title_match(a1, b1, c1)),\n",
    "                args=(que_1, input_query, all_items, tags))\n",
    "    que_2 = queue.Queue()\n",
    "    t2 = Thread(target=lambda q2, a2, b2, c2: q2.put(\n",
    "                check_exact_title_code(a2, b2, c2)),\n",
    "                args=(que_2, input_query, all_items, tags))\n",
    "    que_3 = queue.Queue()\n",
    "    t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                check_exact_skill_match(a3, b3)),\n",
    "                args=(que_3, input_query, all_items))\n",
    "    que_4 = queue.Queue()\n",
    "    t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                check_exact_skill_code(a4, b4)),\n",
    "                args=(que_4, input_query, all_items))\n",
    "    que_5 = queue.Queue()\n",
    "    t5 = Thread(target=lambda q5, a5, b5, c5: q5.put(\n",
    "                check_for_category(a5, b5, c5)),\n",
    "                args=(que_5, input_query, seco_category, prim_category))\n",
    "    que_6 = queue.Queue()\n",
    "    t6 = Thread(target=lambda q6, a6, b6: q6.put(\n",
    "                check_for_market_place(a6, b6)),\n",
    "                args=(que_6, input_query, market_place))\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "    t4.start()\n",
    "    t5.start()\n",
    "    t6.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "    t4.join()\n",
    "    t5.join()\n",
    "    t6.join()\n",
    "\n",
    "    scm, pcm = que_5.get()\n",
    "    if (0 != scm):\n",
    "        temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "        temp_dict[\"secondaryCategory\"] = scm\n",
    "    if (0 != pcm):\n",
    "        temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "        temp_dict[\"primaryCategory\"] = pcm\n",
    "\n",
    "    title_match, title_name_tags = que_1.get()\n",
    "    title_code_match_flag, title_code_tags = que_2.get()\n",
    "    skill_match, skill_name_tags = que_3.get()\n",
    "    skill_code_match_flag, skill_code_tags = que_4.get()\n",
    "\n",
    "    if ((1 == title_match) and (0 == title_code_match_flag) and\n",
    "            (0 == skill_code_match_flag)):\n",
    "        temp_dict[\"activityNameMatchFlag\"] = \"yes\"\n",
    "        temp_dict[\"activityName\"] = input_query\n",
    "        temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"flagProficiency\"] = \"no\"\n",
    "        temp_dict[\"didYouMean\"] = \"no\"\n",
    "        temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "        if (1 == skill_match):\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "            temp_dict[\"skillName\"] = input_query.lower()\n",
    "            temp_dict[\"userSearchTags\"] = skill_name_tags.split(\" \")\n",
    "        else:\n",
    "            print(\"Title name found without skill_name\")\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "            temp_dict[\"userSearchTags\"] = title_name_tags\n",
    "            print(temp_dict[\"userSearchTags\"])\n",
    "        return temp_dict\n",
    "\n",
    "    if ((1 == title_code_match_flag) and (0 == title_match) and\n",
    "            (0 == skill_code_match_flag)):\n",
    "        temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"activityCodeMatchFlag\"] = \"yes\"\n",
    "        temp_dict[\"activityCode\"] = input_query\n",
    "        temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"flagProficiency\"] = \"no\"\n",
    "        temp_dict[\"didYouMean\"] = \"no\"\n",
    "        temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "        if (1 == skill_match):\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "            temp_dict[\"skillName\"] = input_query.lower()\n",
    "            temp_dict[\"userSearchTags\"] = skill_name_tags.split(\" \")\n",
    "        else:\n",
    "            print(\"Title code found without skill_name\")\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "            temp_dict[\"userSearchTags\"] = title_code_tags\n",
    "        return temp_dict\n",
    "\n",
    "    if ((1 == skill_match) and (0 == skill_code_match_flag) and\n",
    "            (0 == title_match) and (0 == title_code_match_flag)):\n",
    "        temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "        temp_dict[\"skillName\"] = input_query.lower()\n",
    "        temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"flagProficiency\"] = \"no\"\n",
    "        temp_dict[\"didYouMean\"] = \"no\"\n",
    "        temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "        temp_dict[\"userSearchTags\"] = skill_name_tags.split(\" \")\n",
    "        return temp_dict\n",
    "\n",
    "    if ((1 == skill_code_match_flag) and (0 == skill_match) and\n",
    "            (0 == title_match) and (0 == title_code_match_flag)):\n",
    "        temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"skillCodeMatchFlag\"] = \"yes\"\n",
    "        temp_dict[\"skillCode\"] = input_query\n",
    "        temp_dict[\"flagProficiency\"] = \"no\"\n",
    "        temp_dict[\"didYouMean\"] = \"no\"\n",
    "        temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "        temp_dict[\"userSearchTags\"] = skill_code_tags\n",
    "        return temp_dict\n",
    "\n",
    "    market_place_flag = que_6.get()\n",
    "    if (0 != market_place_flag):\n",
    "        temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "        temp_dict[\"flagProficiency\"] = \"no\"\n",
    "        temp_dict[\"didYouMean\"] = \"no\"\n",
    "        temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "        temp_dict[\"marketPlaceFlag\"] = \"yes\"\n",
    "        temp_dict[\"marketPlace\"] = market_place_flag\n",
    "        temp_dict[\"userSearchTags\"] = market_place_flag\n",
    "        return temp_dict\n",
    "    ##-------------------------------------##\n",
    "\n",
    "    ##-------------------------------------##\n",
    "    temp_dict[\"flagProficiency\"] = \"no\"\n",
    "    temp_dict[\"phrase\"] = \"no\"\n",
    "    temp_dict[\"userSearchTags\"] = \"no\"\n",
    "    temp_dict[\"didYouMean\"] = \"no\"\n",
    "    temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "    temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "    temp_dict[\"deliveryModeFlag\"] = \"no\"\n",
    "    temp_dict[\"secondaryCategoryFlag\"] = \"no\"\n",
    "    temp_dict[\"primaryCategoryFlag\"] = \"no\"\n",
    "\n",
    "    # ---- 100% matching of the Activity Label or Lo Type or Delivery Mode\n",
    "    ##---- nothing else in the input ----##\n",
    "    activity_label_or_lo_type_flag = 0\n",
    "    activity_label_or_lo_type_flag = \\\n",
    "        process_whole_match_activity_label_or_lo_type(\n",
    "            input_query,\n",
    "            temp_dict,\n",
    "            keywords_list)\n",
    "    delivery_mode_found = 0\n",
    "    delivery_mode_found = check_for_delivery_mode(\n",
    "        input_query,\n",
    "        temp_dict,\n",
    "        delivery_mode)\n",
    "    if (1 == activity_label_or_lo_type_flag) or (1 == delivery_mode_found):\n",
    "        return (temp_dict)\n",
    "    ##------------------------------------##\n",
    "\n",
    "    ##------------------------------------##\n",
    "    associated_tags = \"no\"\n",
    "    temp_dict[\"userSearchTags\"] = associated_tags\n",
    "    sample = input_query\n",
    "    #print(\"input = \", sample)\n",
    "\n",
    "    tokens = sample.split(\" \")\n",
    "    #print(tokens)\n",
    "    #print(\"Length: \", len(tokens))\n",
    "\n",
    "    tokens_str = \" \".join(tokens)\n",
    "    #print(\"tokens_str: [%s]\" % tokens_str)\n",
    "\n",
    "    ##---- input has only single word ----##\n",
    "    if (1 == len(tokens)):\n",
    "        #print(\"CHK -1\")\n",
    "        temp_dict_processed = process_single_word_input(\n",
    "            tokens,\n",
    "            temp_dict,\n",
    "            tags_2,\n",
    "            proficiency_level)\n",
    "        return (temp_dict_processed)\n",
    "    ##------------------------------------##\n",
    "\n",
    "    ##---- input has only two words ------##\n",
    "    if (2 == len(tokens)):\n",
    "        #print(tokens)\n",
    "        #print(\"CHK -2\")\n",
    "        process_two_words_input(\n",
    "            tokens,\n",
    "            temp_dict,\n",
    "            seco_category,\n",
    "            prim_category,\n",
    "            delivery_mode,\n",
    "            market_place,\n",
    "            keywords_list,\n",
    "            tags_2,\n",
    "            all_items,\n",
    "            proficiency_level)\n",
    "        return (temp_dict)\n",
    "    ##-------------------------------------##\n",
    "\n",
    "    ##---- input has more than 2 words ----##\n",
    "    else:\n",
    "        #print(\"CHK -3\")\n",
    "        input_having_keywords_flag = 0\n",
    "        search_query_lwr = sample.lower()\n",
    "\n",
    "        input_having_keywords_flag, search_query_lwr = process_input_having_keywords(\n",
    "            search_query_lwr,\n",
    "            temp_dict,\n",
    "            keywords_list,\n",
    "            seco_category,\n",
    "            prim_category,\n",
    "            proficiency_level,\n",
    "            vowel_list)\n",
    "        #print(\"input_having_keywords_flag: [%s]\" % input_having_keywords_flag)\n",
    "\n",
    "        input_having_dm_flag = 0\n",
    "\n",
    "        if (0 == input_having_dm_flag):\n",
    "            input_having_dm_flag, search_query_lwr = process_input_having_delivery_mode(\n",
    "                search_query_lwr,\n",
    "                temp_dict,\n",
    "                delivery_mode,\n",
    "                proficiency_level,\n",
    "                vowel_list)\n",
    "        #print(\"input_having_dm_flag: [%s]\" % input_having_dm_flag)\n",
    "\n",
    "        input_having_market_place_flag = 0\n",
    "        input_having_market_place_flag, \\\n",
    "            search_query_lwr = process_input_having_market_place(\n",
    "                search_query_lwr,\n",
    "                temp_dict,\n",
    "                market_place,\n",
    "                proficiency_level,\n",
    "                vowel_list)\n",
    "        #print(\"input_having_market_place_flag\")\n",
    "        ##--------------- SPECIAL CASES: Arbitrary User Input -------------##\n",
    "        ##---- Example: Natural Language Processing -----------------------##\n",
    "        ##---- Example: I need project training on Internet of Things -----##\n",
    "        ##---- Example: Need help on Long Short Term Memory ---------------##\n",
    "        if ((0 == input_having_keywords_flag) and (0 == input_having_dm_flag)\n",
    "                and (0 == input_having_market_place_flag)):\n",
    "            #print(\"CHK -3bb\")\n",
    "            pl_found_flag = 0\n",
    "\n",
    "            for loop_cnt in range(0, len(proficiency_level)):\n",
    "                if (proficiency_level[loop_cnt].lower() in search_query_lwr):\n",
    "                    search_query_lwr = search_query_lwr.replace(\n",
    "                        proficiency_level[loop_cnt]. lower(), \"\")\n",
    "                    temp_dict[\"flagProficiency\"] = \"yes\"\n",
    "                    temp_dict[\"userProficiency_search\"] = \\\n",
    "                        proficiency_level[loop_cnt].lower()\n",
    "                    pl_found_flag = 1\n",
    "                    break\n",
    "            search_query_cp = copy.copy(search_query_lwr)\n",
    "            if (0 == pl_found_flag):\n",
    "                temp_dict[\"flagProficiency\"] = \"no\"\n",
    "\n",
    "            scm, pcm = check_for_category(search_query_lwr.strip(),\n",
    "                                          seco_category, prim_category)\n",
    "            if (0 != scm):\n",
    "                temp_dict[\"secondaryCategory\"] = scm\n",
    "            if (0 != pcm):\n",
    "                temp_dict[\"primaryCategory\"] = pcm\n",
    "\n",
    "            if ((0 == scm) and (0 == pcm)):\n",
    "                search_query_lwr_tokens = search_query_lwr.split()\n",
    "                #print(search_query_lwr_tokens)\n",
    "                search_query_lwr_tokens_length = len(search_query_lwr_tokens)\n",
    "\n",
    "                for j in range(0, len(seco_category)):\n",
    "                    temp_item = seco_category[j].lower()\n",
    "                    temp_item_tokens = temp_item.split()\n",
    "                    first_seco_match = 0\n",
    "                    for lc_2 in range(0, len(search_query_lwr_tokens)):\n",
    "                        if (search_query_lwr_tokens[lc_2]\n",
    "                                == temp_item_tokens[0]):\n",
    "                            first_seco_match = 1\n",
    "                            break\n",
    "                    if ((1 == first_seco_match) and (\n",
    "                            temp_item in search_query_lwr)):\n",
    "                        temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"secondaryCategory\"] = temp_item\n",
    "                        break\n",
    "\n",
    "                for k in range(0, len(prim_category)):\n",
    "                    temp_item = prim_category[k].lower()\n",
    "                    temp_item_tokens = temp_item.split()\n",
    "                    first_prim_match = 0\n",
    "                    for lc_3 in range(0, len(search_query_lwr_tokens)):\n",
    "                        if (search_query_lwr_tokens[lc_3]\n",
    "                                == temp_item_tokens[0]):\n",
    "                            first_prim_match = 1\n",
    "                            break\n",
    "                    if ((1 == first_prim_match) and (\n",
    "                            temp_item in search_query_lwr)):\n",
    "                        temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                        temp_dict[\"primaryCategory\"] = temp_item\n",
    "                        break\n",
    "\n",
    "            if ((\"yes\" == temp_dict[\"secondaryCategoryFlag\"]) or\n",
    "                    (\"yes\" == temp_dict[\"primaryCategoryFlag\"])):\n",
    "                np_extractor_object = Noun_Phrase_Extraction(search_query_cp)\n",
    "            else:\n",
    "                np_extractor_object = Noun_Phrase_Extraction(search_query_lwr)\n",
    "            np_result = np_extractor_object.extract()\n",
    "            #print(\"Debug print: np_result = \", np_result)\n",
    "            if (0 == len(np_result)):\n",
    "                np_result_2 = np_extractor_object.extract_2()\n",
    "                #print(np_result_2)\n",
    "                np_result_3 = [item for item in np_result_2 if\n",
    "                               item not in vowel_list]\n",
    "                #print(\"np_result_3: \", np_result_3)\n",
    "                temp_str = \" \".join(np_result_3)\n",
    "                temp_dict[\"phrase\"] = temp_str\n",
    "            else:\n",
    "                np_result_2 = [item for item in np_result if\n",
    "                               item not in vowel_list]\n",
    "                #print(\"np_result_2: \", np_result_2)\n",
    "                temp_str = \" \".join(np_result_2)\n",
    "                temp_dict[\"phrase\"] = temp_str\n",
    "            temp_dict[\"learningObjectFlag\"] = \"no\"\n",
    "        #print (temp_dict)\n",
    "        ##----------------------------------------------------------------##\n",
    "\n",
    "        ##----------------------------------------------------------------##\n",
    "        # Checking the nlp extracted phrase with skill name\n",
    "        #print (\"nlp extracted phrase becomes: \", temp_dict[\"phrase\"])\n",
    "        que_1 = queue.Queue()\n",
    "        t1 = Thread(target=lambda q1, a1, b1: q1.put(\n",
    "            check_exact_skill_match(a1, b1)),\n",
    "            args=(que_1, temp_dict[\"phrase\"], all_items))\n",
    "        que_2 = queue.Queue()\n",
    "        t2 = Thread(target=lambda q2, a2, b2, c2: q2.put(\n",
    "            check_for_category(a2, b2, c2)),\n",
    "            args=(que_2, temp_dict[\"phrase\"], seco_category, prim_category))\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        scm, pcm = que_2.get()\n",
    "        if (0 != scm):\n",
    "            temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "            temp_dict[\"secondaryCategory\"] = scm\n",
    "        if (0 != pcm):\n",
    "            temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "            temp_dict[\"primaryCategory\"] = pcm\n",
    "\n",
    "        skill_match, associated_tags = que_1.get()\n",
    "        #print(\"associated_tags: \", associated_tags)\n",
    "        if (1 == skill_match):\n",
    "            temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "            temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "            temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "            temp_dict[\"skillName\"] = temp_dict[\"phrase\"]\n",
    "            temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "            temp_dict[\"userSearchTags\"] = associated_tags.split(\" \")\n",
    "            #print(temp_dict)\n",
    "            return (temp_dict)\n",
    "\n",
    "        # checking for the nlp phrase for title code and skill code\n",
    "        else:\n",
    "            #phrase_tokens = word_tokenize(temp_dict[\"phrase\"])\n",
    "            phrase_tokens = temp_dict[\"phrase\"].split(\" \")\n",
    "            title_code_match = 0\n",
    "            skill_code_match = 0\n",
    "            que_1 = queue.Queue()\n",
    "            t1 = Thread(target=lambda q1, a1, b1: q1.put(\n",
    "                check_title_code(a1, b1)),\n",
    "                args=(que_1, phrase_tokens, all_items))\n",
    "            que_2 = queue.Queue()\n",
    "            t2 = Thread(target=lambda q2, a2, b2: q2.put(\n",
    "                check_skill_code(a2, b2)),\n",
    "                args=(que_2, phrase_tokens, all_items))\n",
    "            t1.start()\n",
    "            t2.start()\n",
    "            t1.join()\n",
    "            t2.join()\n",
    "\n",
    "            title_code_match, title_code, associated_tags = que_1.get()\n",
    "            if (1 == title_code_match):\n",
    "                temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "                temp_dict[\"activityCodeMatchFlag\"] = \"yes\"\n",
    "                temp_dict[\"activityCode\"] = title_code\n",
    "                temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "                temp_dict[\"skillCodeMatchFlag\"] = \"no\"\n",
    "                temp_dict[\"userSearchTags\"] = associated_tags\n",
    "                #print (temp_dict)\n",
    "                return (temp_dict)\n",
    "\n",
    "            skill_code_match, skill_code, associated_tags = que_2.get()\n",
    "            if (1 == skill_code_match):\n",
    "                temp_dict[\"activityNameMatchFlag\"] = \"no\"\n",
    "                temp_dict[\"activityCodeMatchFlag\"] = \"no\"\n",
    "                temp_dict[\"skillNameMatchFlag\"] = \"no\"\n",
    "                temp_dict[\"skillCodeMatchFlag\"] = \"yes\"\n",
    "                temp_dict[\"skillCode\"] = skill_code\n",
    "                temp_dict[\"userSearchTags\"] = associated_tags\n",
    "                #print(temp_dict)\n",
    "                return (temp_dict)\n",
    "\n",
    "            # handling of C# present in the input string\n",
    "            if (\"c#\" == temp_dict[\"phrase\"]):\n",
    "                tags_str = temp_dict[\"phrase\"]\n",
    "                temp_dict[\"userSearchTags\"] = temp_dict[\"phrase\"]\n",
    "            else:\n",
    "                que_3 = queue.Queue()\n",
    "                t3 = Thread(target=lambda q3, a3, b3: q3.put(\n",
    "                    handle_nlp_extracted_phrase(a3, b3)),\n",
    "                    args=(que_3, temp_dict[\"phrase\"], tags_2))\n",
    "                que_4 = queue.Queue()\n",
    "                t4 = Thread(target=lambda q4, a4, b4: q4.put(\n",
    "                    check_for_did_you_mean(a4, b4)),\n",
    "                    args=(que_4, temp_dict[\"phrase\"], tags_2))\n",
    "\n",
    "                t3.start()\n",
    "                t4.start()\n",
    "                t3.join()\n",
    "                t4.join()\n",
    "\n",
    "                associated_tags = que_3.get()\n",
    "                if (0 != len(associated_tags)):\n",
    "                    temp_dict[\"userSearchTags\"] = associated_tags\n",
    "\n",
    "                dym_val = que_4.get()\n",
    "                if (None is not dym_val):\n",
    "                    dym_val_1 = dym_val.split()\n",
    "                    #print (dym_val_1)\n",
    "                    dym_val_2 = list(map(lambda x: x.lower(), dym_val_1))\n",
    "                    #print (dym_val_2)\n",
    "                    if (len(dym_val_2) == len(set(dym_val_2))):\n",
    "                        temp_dict[\"didYouMean\"] = string.capwords(dym_val)\n",
    "                else:\n",
    "                    temp_dict[\"didYouMean\"] = \"no\"\n",
    "                #print(temp_dict[\"userSearchTags\"])\n",
    "                if (1 < len(temp_dict[\"userSearchTags\"])):\n",
    "                    tags_str = \" \".join(temp_dict[\"userSearchTags\"])\n",
    "                else:\n",
    "                    tags_str = \"\".join(temp_dict[\"userSearchTags\"])\n",
    "            #print(\"tags_str ABC-Chk: [%s]\" % tags_str)\n",
    "            skill_match, skill_name_tags = check_exact_skill_match(tags_str,\n",
    "                                                                   all_items)\n",
    "            if (1 == skill_match):\n",
    "                temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                temp_dict[\"skillName\"] = tags_str\n",
    "            else:\n",
    "                skill_match, skill_name_tags = check_for_skill_match(tags_str,\n",
    "                                                                     all_items)\n",
    "                if (1 == skill_match):\n",
    "                    temp_dict[\"skillNameMatchFlag\"] = \"yes\"\n",
    "                    temp_dict[\"skillName\"] = skill_name_tags\n",
    "\n",
    "        #print (temp_dict)\n",
    "        print(\"Prepared Tags: \", temp_dict[\"userSearchTags\"])\n",
    "        if (isinstance(temp_dict[\"userSearchTags\"], list)):\n",
    "            for i in range(0, len(temp_dict[\"userSearchTags\"])):\n",
    "                scm, pcm = check_for_category(temp_dict[\"userSearchTags\"][i],\n",
    "                                              seco_category, prim_category)\n",
    "                if (0 != scm):\n",
    "                    temp_dict[\"secondaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"secondaryCategory\"] = scm\n",
    "                    break\n",
    "                if (0 != pcm):\n",
    "                    temp_dict[\"primaryCategoryFlag\"] = \"yes\"\n",
    "                    temp_dict[\"primaryCategory\"] = pcm\n",
    "                    break\n",
    "        return (temp_dict)\n",
    "\n",
    "# This function is used to read the several JSON files to be used in search\n",
    "# application. This function accepts the comfig_data object as the parameter.\n",
    "\n",
    "\n",
    "def init():\n",
    "    global all_items, tags, tags_2, tag_stopwords_2, prim_category, \\\n",
    "        seco_category, delivery_mode, market_place, keywords_list\n",
    "    skill_title_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                    \"models/CombinedTag.json\")\n",
    "    try:\n",
    "        with open(skill_title_file) as title_skill_json_file:\n",
    "            all_items = json.load(title_skill_json_file)\n",
    "    except ValueError as error:\n",
    "        print(\"Error type:\", type(error))\n",
    "        print(\"json.loads() ValueError for JSON object:\", error)\n",
    "    all_tags = list(map(itemgetter(\"tag\"), all_items))\n",
    "    print(\"Total length of all_tags: \", len(all_tags))\n",
    "\n",
    "    # checking for none type element\n",
    "    Not_none_values = filter(None.__ne__, all_tags)\n",
    "    tags = list(Not_none_values)\n",
    "    #print (\"Total length of tags: \", len(tags))\n",
    "\n",
    "    list_of_tags = ', '.join(tags).split(', ')\n",
    "    unique_tags = set(list_of_tags)\n",
    "    tags_2 = list(unique_tags)\n",
    "    #print (tags_2)\n",
    "    ##---- Tag Stopword file handling ----##\n",
    "    tag_stopwords_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                      \"models/tag_stpwords.txt\")\n",
    "    tag_stopwords = open(tag_stopwords_file, 'r').read().split('\\n')\n",
    "    tag_stopwords_2 = [x.lower() for x in tag_stopwords]\n",
    "    #print (\"tag_stopwords_2\")\n",
    "    #print (len(tag_stopwords_2))\n",
    "\n",
    "    ##---- LO file handling ----##\n",
    "    keywords_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                 \"models/lo_keywords.csv\")\n",
    "    keywords_list = pd.read_csv(keywords_file, low_memory=False,\n",
    "                                encoding='ISO-8859-1', error_bad_lines=False,\n",
    "                                warn_bad_lines=False, index_col=False)\n",
    "    # print(keywords_list)\n",
    "\n",
    "    ##---- Category handling -------------##\n",
    "    primary_category_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                         \"models/primary_category.json\")\n",
    "    prim_category = json.loads(open(primary_category_file, 'r').read().\n",
    "                               splitlines()[0])\n",
    "    # print(prim_category)\n",
    "    #print (len(prim_category))\n",
    "\n",
    "    secondary_category_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                           \"models/secondary_category.json\")\n",
    "    seco_category = json.loads(open(secondary_category_file, 'r').read().\n",
    "                               splitlines()[0])\n",
    "    # print(seco_category)\n",
    "    #print (len(seco_category))\n",
    "\n",
    "    ##---- Delivery Mode -----------------##\n",
    "    delivery_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                 \"models/DeliveryMode.json\")\n",
    "    delivery_mode = json.loads(open(delivery_file, 'r').read().\n",
    "                               splitlines()[0])\n",
    "\n",
    "    #print (delivery_mode)\n",
    "    #print (len(delivery_mode))\n",
    "\n",
    "    ##---- Market Place ------------------##\n",
    "\n",
    "    market_place_file = os.path.join(os.getenv('AZUREML_MODEL_DIR'),\n",
    "                                     \"models/MarketPlaceName.json\")\n",
    "    market_place = json.loads(open(market_place_file, 'r').read().\n",
    "                              splitlines()[0])\n",
    "    #print (market_place)\n",
    "    #print (len(market_place))\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# This is the main API function to be used under the development mode. This\n",
    "# function accepts the parameters of the UI output object.\n",
    "\n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        reqBody = request.get_data(False)\n",
    "        data = json.loads(reqBody)\n",
    "        ui_output = data[\"data\"]\n",
    "\n",
    "        #print(\"\\n Considered Input: \\n\", ui_output)\n",
    "\n",
    "        vowel_list = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
    "\n",
    "        proficiency_level = [\n",
    "            \"Beginner\",\n",
    "            \"Basic\",\n",
    "            \"Learner\",\n",
    "            \"Level1\",\n",
    "            \"Level 1\",\n",
    "            \"PL1\",\n",
    "            \"PL 1\",\n",
    "            \"L1\",\n",
    "            \"Intermediate\",\n",
    "            \"Practitioner\",\n",
    "            \"Level2\",\n",
    "            \"Level 2\",\n",
    "            \"PL2\",\n",
    "            \"PL 2\",\n",
    "            \"L2\",\n",
    "            \"Advanced\",\n",
    "            \"Specialist\",\n",
    "            \"Level3\",\n",
    "            \"Level 3\",\n",
    "            \"PL3\",\n",
    "            \"PL 3\",\n",
    "            \"L3\",\n",
    "            \"Expert\",\n",
    "            \"Level4\",\n",
    "            \"Level 4\",\n",
    "            \"PL4\",\n",
    "            \"PL 4\",\n",
    "            \"L4\"]\n",
    "        ##-----------------------------------------------------------------##\n",
    "\n",
    "        ##-- Starter Program ----------------------------------------------##\n",
    "        query_processed_output = process_ui_output(\n",
    "            ui_output,\n",
    "            keywords_list,\n",
    "            all_items,\n",
    "            tags,\n",
    "            tags_2,\n",
    "            prim_category,\n",
    "            seco_category,\n",
    "            delivery_mode,\n",
    "            market_place,\n",
    "            vowel_list,\n",
    "            proficiency_level)\n",
    "        ##-----------------------------------------------------------------##\n",
    "\n",
    "        ##-----------------------------------------------------------------##\n",
    "        # Post Processing and Preparing the Final Result\n",
    "        if (\"phrase\" in query_processed_output):\n",
    "            query_processed_output.pop(\"phrase\")\n",
    "        if (\"deliveryModeFlag\" not in query_processed_output):\n",
    "            query_processed_output[\"deliveryModeFlag\"] = \"no\"\n",
    "        if (\"marketPlaceFlag\" not in query_processed_output):\n",
    "            query_processed_output[\"marketPlaceFlag\"] = \"no\"\n",
    "        # if ((\"activityLabel\" in query_processed_output) and \\\n",
    "            # (0 == len(query_processed_output[\"activityLabel\"]))):\n",
    "            # query_processed_output.pop(\"activityLabel\")\n",
    "        if ((\"learningObject\" in query_processed_output) and\n",
    "                (0 == len(query_processed_output[\"learningObject\"]))):\n",
    "            query_processed_output.pop(\"learningObject\")\n",
    "\n",
    "        temp = query_processed_output[\"userSearchTags\"]\n",
    "        # print(temp)\n",
    "        if (\"no\" == temp):\n",
    "            temp = ui_output[\"Search_String\"].lower().split()\n",
    "        #print(\"query_processed tags: \", temp)\n",
    "        #print (type(temp))\n",
    "\n",
    "        if (isinstance(temp, list)):\n",
    "            processed_tags_list = []\n",
    "            for i in range(0, len(temp)):\n",
    "                temp_2 = ''.join(temp[i]).split(', ')\n",
    "                processed_tags_list.append(temp_2)\n",
    "            #print (processed_tags_list)\n",
    "            #print (len(processed_tags_list))\n",
    "            processed_tags_list = list(\n",
    "                chain.from_iterable(processed_tags_list))\n",
    "            #print (processed_tags_list)\n",
    "            #print (len(processed_tags_list))\n",
    "            processed_tags_list_2 = []\n",
    "            for i in range(0, len(processed_tags_list)):\n",
    "                if ((0 != len(processed_tags_list[i])) and\n",
    "                        (processed_tags_list[i] not in processed_tags_list_2)):\n",
    "                    processed_tags_list_2.append(processed_tags_list[i])\n",
    "            #print(processed_tags_list_2)\n",
    "            #print (len(processed_tags_list_2))\n",
    "            processed_tags_list_3 = list(set(processed_tags_list_2) &\n",
    "                                         set(tag_stopwords_2))\n",
    "            query_processed_output[\"userSearchTags\"] = \\\n",
    "                list(set(processed_tags_list_2) - set(processed_tags_list_3))\n",
    "            #print(   \"query_processed_output['tags']: \",query_processed_output[\"userSearchTags\"])\n",
    "            if (1 == len(query_processed_output[\"userSearchTags\"])):\n",
    "                query_processed_output[\"userSearchTags\"] = \\\n",
    "                    \"\".join(query_processed_output[\"userSearchTags\"])\n",
    "            else:\n",
    "                query_processed_output[\"userSearchTags\"] = \\\n",
    "                    \", \".join(query_processed_output[\"userSearchTags\"])\n",
    "\n",
    "        query_processed_output[\"segment\"] = ui_output[\"Segment\"]\n",
    "        if ((\"secondaryCategory\" in query_processed_output) or\n",
    "                (\"primaryCategory\" in query_processed_output)):\n",
    "            if ((\"no\" == query_processed_output[\"userSearchTags\"]) and\n",
    "                    (0 != len(query_processed_output[\"didYouMean\"]))):\n",
    "                query_processed_output[\"userSearchTags\"] = \\\n",
    "                    query_processed_output[\"didYouMean\"]\n",
    "                query_processed_output[\"didYouMean\"] = \"no\"\n",
    "\n",
    "        if ((\"skillName\" in query_processed_output) and\n",
    "                (isinstance(query_processed_output[\"skillName\"], list))):\n",
    "            query_processed_output[\"skillName\"] = \\\n",
    "                \"\".join(query_processed_output[\"skillName\"])\n",
    "        # did_you_mean\n",
    "        if (query_processed_output[\"didYouMean\"] == \"no\"):\n",
    "            query_processed_output[\"didYouMeanFlag\"] = \"no\"\n",
    "            query_processed_output[\"didYouMean\"] = \"\"\n",
    "        else:\n",
    "            query_processed_output[\"didYouMeanFlag\"] = \"yes\"\n",
    "        # skill_name\n",
    "        if (query_processed_output[\"skillNameMatchFlag\"] == \"no\"):\n",
    "            query_processed_output[\"skillName\"] = \"\"\n",
    "        # skill_code\n",
    "        if (query_processed_output[\"skillCodeMatchFlag\"] == \"no\"):\n",
    "            query_processed_output[\"skillCode\"] = \"\"\n",
    "        # Proficiency Level\n",
    "        if (query_processed_output[\"flagProficiency\"] == \"no\"):\n",
    "            query_processed_output[\"userProficiency_search\"] = \"\"\n",
    "        else:\n",
    "            if ((query_processed_output[\"userProficiency_search\"] == \"beginner\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"basic\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"learner\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level1\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level 1\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"pl1\") or\n",
    "                    (query_processed_output[\"userProficiency_search\"] == \"pl 1\")):\n",
    "                query_processed_output[\"userProficiency_search\"] = 1\n",
    "            if ((query_processed_output[\"userProficiency_search\"] == \"intermediate\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"practitioner\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level2\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level 2\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"pl2\") or\n",
    "                    (query_processed_output[\"userProficiency_search\"] == \"pl 2\")):\n",
    "                query_processed_output[\"userProficiency_search\"] = 2\n",
    "            if ((query_processed_output[\"userProficiency_search\"] == \"advanced\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"specialist\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level3\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level 3\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"pl3\") or\n",
    "                    (query_processed_output[\"userProficiency_search\"] == \"pl 3\")):\n",
    "                query_processed_output[\"userProficiency_search\"] = 3\n",
    "            if ((query_processed_output[\"userProficiency_search\"] == \"expert\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level4\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"level 4\") or\n",
    "                (query_processed_output[\"userProficiency_search\"] == \"pl4\") or\n",
    "                    (query_processed_output[\"userProficiency_search\"] == \"pl 4\")):\n",
    "                query_processed_output[\"userProficiency_search\"] == 4\n",
    "        # Activity Code\n",
    "        if (query_processed_output[\"activityCodeMatchFlag\"] == \"no\"):\n",
    "            query_processed_output[\"activityCode\"] = \"\"\n",
    "        # Activity Name\n",
    "        if (query_processed_output[\"activityNameMatchFlag\"] == \"no\"):\n",
    "            query_processed_output[\"activityName\"] = \"\"\n",
    "        # Learning Object\n",
    "        if (query_processed_output[\"learningObjectFlag\"] == \"no\"):\n",
    "            query_processed_output[\"learningObject\"] = \"\"\n",
    "        # Market Place\n",
    "        if (query_processed_output[\"marketPlaceFlag\"] == \"no\"):\n",
    "            query_processed_output[\"marketPlace\"] = \"\"\n",
    "        # Delivery Mode\n",
    "        if (query_processed_output[\"deliveryModeFlag\"] == \"no\"):\n",
    "            query_processed_output[\"deliveryMode\"] = \"\"\n",
    "        # Primary Category\n",
    "        if (query_processed_output[\"primaryCategoryFlag\"] == \"no\"):\n",
    "            query_processed_output[\"primaryCategory\"] = \"\"\n",
    "        # Secondary Category\n",
    "        if (query_processed_output[\"secondaryCategoryFlag\"] == \"no\"):\n",
    "            query_processed_output[\"secondaryCategory\"] = \"\"\n",
    "\n",
    "        query_processed_output[\"userID\"] = ui_output[\"UserID\"]\n",
    "\n",
    "        query_processed_output[\"userSearchTags\"] = query_processed_output[\"userSearchTags\"].replace(\n",
    "            \"/\", \", \")\n",
    "        query_processed_output = dict(sorted(query_processed_output.items()))\n",
    "        #print(\"query_processed_output: \", query_processed_output)\n",
    "        # result_out=query_processed_output.to_json()\n",
    "        NLU_response = AMLResponse(query_processed_output, 200, json_str=True)\n",
    "        return NLU_response\n",
    "#------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment yml file for RunConfiguration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in academy.yml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'search_web_service/academy.yml'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "import shutil\n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"pandas\")\n",
    "myenv.add_conda_package(\"numpy\")\n",
    "myenv.add_conda_package(\"azure-storage\")\n",
    "myenv.add_conda_package(\"azure-storage-blob\")\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"nltk\")\n",
    "\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file =\"academy.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "shutil.copyfile('academy.yml', folder_name+\"/academy.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create InferenceConfig for the model deployment to webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"search_api.py\",\n",
    "                                   conda_file=\"academy.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Model instance that will be used by the AKS Web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model(ws, name='academy-models-search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting with the AKS Cluster and Deploy webservice into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-07-13 12:44:04+00:00 Creating Container Registry if not exists.\n",
      "2021-07-13 12:44:04+00:00 Registering the environment.\n",
      "2021-07-13 12:44:05+00:00 Use the existing image..\n",
      "2021-07-13 12:44:10+00:00 Checking the status of deployment mylearning-searchphraseextract..\n",
      "2021-07-13 12:46:03+00:00 Checking the status of inference endpoint mylearning-searchphraseextract.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "aks_target = AksCompute(ws,\"MLMYLEARNPAKS02\")\n",
    "\n",
    "#deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 2)\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 8)\n",
    "                                                       \n",
    "\n",
    "service = Model.deploy(ws, \"mylearning-searchphraseextract\", \n",
    "                       [model], \n",
    "                       inference_config, \n",
    "                       deployment_config, \n",
    "                       aks_target,overwrite=True)\n",
    "\n",
    "\n",
    "#service_name = \"mylearning-searchphraseextract\"\n",
    "#service = Webservice(name=service_name, workspace=ws)\n",
    "#service.update(inference_config=inference_config,\n",
    "#               autoscale_enabled=True,\n",
    "#               autoscale_min_replicas=2,\n",
    "#               autoscale_max_replicas=2,\n",
    "#               cpu_cores=1,memory_gb=8,\n",
    "#               enable_app_insights=True)\n",
    "\n",
    "# finally:\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "#print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the URL and the Key in Keyvault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvault = ws.get_default_keyvault()\n",
    "key1, key2 = service.get_keys()\n",
    "\n",
    "keyvault.set_secret(name = 'ml-search-nlu-tag-url', value = service.scoring_uri)\n",
    "keyvault.set_secret(name = 'ml-search-nlu-tag-url-key1', value = key1)\n",
    "keyvault.set_secret(name = 'ml-search-nlu-tag-url-key2', value = key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service.scoring_uri, key1, key2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger File to initiate the next pipeline of Relevance Score Ranking model registering and AKS webservice deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading triggerrscore.txt\n",
      "Uploaded triggerrscore.txt, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_aiainputtriggerrscore"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "f = open(\"triggerrscore.txt\", \"w\")\n",
    "f.write(f\"Trigger the Relevance score module i.e. to register model and deploy to aks web service as of {current_date}\")\n",
    "f.close()\n",
    "\n",
    "def_blob_store = Datastore(ws, \"aiainputtriggerrscore\")\n",
    "\n",
    "def_blob_store.upload_files(files=['triggerrscore.txt'], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-06a732515c2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
